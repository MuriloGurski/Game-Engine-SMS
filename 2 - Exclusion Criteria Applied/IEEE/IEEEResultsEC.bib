@INPROCEEDINGS{10585437,
  author={Fransson, Emil and Hermansson, Jonatan and Hu, Yan},
  booktitle={2024 IEEE Gaming, Entertainment, and Media Conference (GEM)}, 
  title={A Comparison of Performance on WebGPU and WebGL in the Godot Game Engine}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={WebGL has been the standard API for rendering graphics on the web over the years. A new technology, WebGPU, has been set to release in 2023 and utilizes many of the novel rendering approaches and features common for the native modern graphics APIs, such as Vulkan. Currently, very limited research exists regarding WebGPU's rasterization capabilities. In particular, no research exists about its capabilities when used as a rendering backend in game engines. This paper aims to investigate performance differences between WebGL and WebGPU. It is done in the context of the game engine Godot, and the measured performance is that of the CPU and GPU frame time. The results show that WebGPU performs better than WebGL when used as a rendering backend in Godot, for both the games tests and the synthetic tests. The comparisons clearly show that WebGPU performs faster in mean CPU and GPU frame time.},
  keywords={Graphics;Graphics processing units;Entertainment industry;Games;Media;Rendering (computer graphics);Particle measurements;Game Engine;Performance Overhead;Rendering;WebGPU;WebGL},
  doi={10.1109/GEM61861.2024.10585437},
  ISSN={2766-6530},
  month={June},}

@INPROCEEDINGS{4592756,
  author={dos Santos, Selan Rodrigues and de Oliveira, Jauvane Cavalvante and Fraga, Luciane Machado and Trenhago, Paulo Roberto and Malfatti, Silvano Maneck},
  booktitle={2008 IEEE Conference on Virtual Environments, Human-Computer Interfaces and Measurement Systems}, 
  title={Using a rendering engine to support the development of immersive virtual reality applications}, 
  year={2008},
  volume={},
  number={},
  pages={74-79},
  abstract={This work presents the features of a flexible realtime 3D graphics engine aimed at the development of multimedia applications and collaborative virtual environments. The engine, called EnCIMA (Engine for Collaborative and Immersive Multimedia Applications), enables a quick development process of applications by providing a high level interface, which has been implemented using the C++ object-oriented programming paradigm. Important characteristics of the engine are the integration of several real time graphics techniques needed by visualization applications; access to network connection management to support collaboration; 3D sound capability; the support to various specialized interaction equipments such as 3D mice, haptic devices, 3D motion trackers, data-gloves, joypads, force feedback joysticks, and; the capacity to have rendering computation and Physics simulation assigned to GPUs and PPUs, respectively. The engine also enables the developer to choose how the scene should be rendered to, i.e. using standard display devices, stereoscopy, or even several simultaneous projection for spatially immersive displays. As part of the evaluation process, we have compared the performance of EnCIMA to a game engine and two scene graph toolkits, through the use of a testbed application.},
  keywords={Engines;Three dimensional displays;Graphics;Collaboration;Solid modeling;Games;Haptic interfaces;Virtual reality engine;immersive application;real time rendering;collaborative virtual reality},
  doi={10.1109/VECIMS.2008.4592756},
  ISSN={1944-9410},
  month={July},}

@INPROCEEDINGS{6549420,
  author={Luo, Xun},
  booktitle={2013 IEEE Virtual Reality (VR)}, 
  title={Using game engine to enhance mobility modeling in network simulations}, 
  year={2013},
  volume={},
  number={},
  pages={177-178},
  abstract={Mobility modeling is important for network simulation. However, Random Waypoint model and its variants fail to satisfactorily depict mobile users' movement patterns with fidelity. Two features of a game engine, namely character AI and pathfinding can be utilized to enhance mobility modeling in network simulations. This demo builds a virtual scene of typical office environment with multiple employees. Movements of the virtual characters are firstly generated and visualized using Random Waypoint model, and then using alternative approaches combining AI-based control with pathfinding. Through comparison it can be clearly observed that the latter improves simulation fidelity significantly.},
  keywords={Solid modeling;Games;Engines;Artificial intelligence;Visualization;Computational modeling;Mobile computing;Game Engine;Mobility Modeling;Network Simulation},
  doi={10.1109/VR.2013.6549420},
  ISSN={2375-5334},
  month={March},}

@INPROCEEDINGS{6000320,
  author={Xiang, Yin and Bee, Ng Kian and Dillon, Roberto},
  booktitle={2011 16th International Conference on Computer Games (CGAMES)}, 
  title={Porting and optimizing Music and Emotion Driven Game Engine from PC platform to PS 3 platform}, 
  year={2011},
  volume={},
  number={},
  pages={70-74},
  abstract={Music and Emotion Driven Game Engine (MEDGE) is a music game engine capable of analyzing emotional content in music real-time. As such, its emotion recognition algorithm complexity is computational intensive. This paper studies the MEDGE performance in quantitative terms when it is ported to PS3's multithreading technology — Cell BE platform. We show the experimental results of the increased performance without compromising accuracy of emotion recognition, and illustrate in comparison with Intel Xeon Quad Core system.},
  keywords={Games;Emotion recognition;Computer architecture;Computers;Microprocessors;Feature extraction;Data mining;emotion;music;optimization;porting;PS3},
  doi={10.1109/CGAMES.2011.6000320},
  ISSN={},
  month={July},}

@INPROCEEDINGS{9951164,
  author={Oakden, Tony and Kavakli, Manolya},
  booktitle={2022 IEEE 42nd International Conference on Distributed Computing Systems Workshops (ICDCSW)}, 
  title={Performance Analysis of RTX Architecture in Virtual Production and Graphics Processing}, 
  year={2022},
  volume={},
  number={},
  pages={215-220},
  abstract={Real-time rendering techniques developed for computer games combined with the improved algorithms and advanced hardware such as the Nvidia Geforce RTX 3000 series of graphic cards improve the quality of the rendered images in CGI. In this paper, our goal is to test the performance of RTX architecture in Virtual Production and graphics processing. We conducted a series of tests for rendering of a scene in Unreal game engine in a Virtual Production studio. Images are rendered in 4K and output to a network distribution system where the image is broken down into a series of smaller images each rendered onto LED screens. The comparison of render times between two graphics workstations using Nvidia RTX A6000 GPU and Nvidia RTX A3090 GPU show that whilst RTX architecture produces better image quality, the gains might not be worth the additional hardware cost required by the high-end graphic cards. It might also be optimal to split the rendering of the scene across multiple computers.},
  keywords={Graphics;Image quality;Costs;Graphics processing units;Production;Computer architecture;Rendering (computer graphics);Real-time rendering;Graphics Processing;Virtual production;Game engineering},
  doi={10.1109/ICDCSW56584.2022.00048},
  ISSN={2332-5666},
  month={July},}

@INPROCEEDINGS{9762415,
  author={Oakden, Tony and Kavakli, Manolya},
  booktitle={2022 14th International Conference on Computer and Automation Engineering (ICCAE)}, 
  title={Graphics Processing in Virtual Production}, 
  year={2022},
  volume={},
  number={},
  pages={61-64},
  abstract={Real-time rendering techniques, developed for computer games, offer great opportunities in Virtual Production. Ray Tracing has been used for CGI movies for many years but it is only recently that its application in real-time has become practical. This is partly due to improved algorithms but mostly advanced hardware such as the Nvidia Geforce RTX 3000 series of cards which provide hardware support for real-time lighting thus improving the quality of the rendered images in CGI. We conducted a series of tests for rendering of a Virtual Production scene in Unreal game engine. Images are rendered in 4K and output to a network distribution system where the image is broken down into a series of smaller images each rendered onto LED screens. Results were plotted to show the comparison of render times between two graphics workstations using Nvidia RTX A6000 GPU cards and Nvidia RTX A3090 GPU. Our findings state that whilst RTX produces better image quality the gains might not be worth the additional hardware cost required by the high-end graphic cards. It might also be optimal to split the rendering of the scene across multiple computers.},
  keywords={Image quality;Graphics;Costs;Graphics processing units;Production;Games;Rendering (computer graphics);graphics processing;virtual production;graphic cards;performance analysis},
  doi={10.1109/ICCAE55086.2022.9762415},
  ISSN={},
  month={March},}

@INPROCEEDINGS{10333229,
  author={Fachada, Nuno and Barreiros, Filipa F. and Lopes, Phil and Fonseca, Micaela},
  booktitle={2023 IEEE Conference on Games (CoG)}, 
  title={Active Learning Prototypes for Teaching Game AI}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Artificial intelligence (AI) in computer games can enhance the player experience by providing more realistic and dynamic interactions with non-player characters and/or the game environment and is, therefore, an essential skill for game development students to acquire. In this paper, we discuss ten active learning prototypes for undergraduate game development students focusing on AI for Games. The prototypes were implemented in the Unity game engine, and each prototype considers a particular technique or set of algorithms. Depending on the prototype, students are required to interact with it on two levels: 1) by running it within the Unity editor, manipulating the respective technique’s parameters, and experimenting and/or playing with the implemented demo or game; or, 2) in addition to the previous level, by actively changing and expanding the provided code to achieve the desired behavior or result. We performed a survey immediately after contact with the prototypes and found that they were easy for the students to manipulate and/or build upon, and most significantly, that they helped students understand the associated techniques and algorithms.},
  keywords={Surveys;Video games;Codes;Education;Prototypes;Focusing;Games;AI for games;AI education;active learning;computer games;game development},
  doi={10.1109/CoG57401.2023.10333229},
  ISSN={2325-4289},
  month={Aug},}

@INPROCEEDINGS{9579618,
  author={Vohera, Chaitya and Chheda, Heet and Chouhan, Dhruveel and Desai, Ayush and Jain, Vijal},
  booktitle={2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Game Engine Architecture and Comparative Study of Different Game Engines}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Nowadays Game Engines have become an integral component of the game development environment. Not only do they accelerate the game development process but also facilitate the integration of gaming modules like animations, graphics, artificial intelligence, and physics using their in-built functionalities. Game Engines also provide a major advantage of reusability of their components making them highly scalable and modifiable. Game engines can be used by the developers to construct and develop games for consoles and different types of platforms such as Android, IOS, Desktop, and many more. This paper eludes the game engine architecture and its constituents and illustrates the features and comparative analysis between four popular game engines namely, Unity, GameMaker, Unreal, and CryEngine. The parameters of this comparison are based on the game engines' technical and non-technical aspects. In conclusion, users will be assisted by the extensive overview provided by this paper in choosing the most preferable engine for their game according to the requirements.},
  keywords={Visualization;Games;Computer architecture;Tools;Animation;Real-time systems;Artificial intelligence;Cry Engine;Game Engine Architecture;GameMaker;Unity;Unreal},
  doi={10.1109/ICCCNT51525.2021.9579618},
  ISSN={},
  month={July},}

@INPROCEEDINGS{7973661,
  author={Polančec, D. and Mekterović, I.},
  booktitle={2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
  title={Developing MOBA games using the Unity game engine}, 
  year={2017},
  volume={},
  number={},
  pages={1510-1515},
  abstract={MOBA (Multiplayer Online Battle Arena) games are currently one of the most popular online video game genres. This paper discusses implementation of a typical MOBA game prototype for Windows platform in a popular game engine Unity 5. The focus is put on using the built-in Unity components in a MOBA setting, developing additional behaviours using Unity's Scripting API for C# and integrating third party components such as the networking engine, 3D models, and particle systems created for use with Unity and available through the Unity Asset Store. A brief overview of useful programming design patterns as well as design patterns already used in Unity is given. Various game state synchronization mechanisms available in the chosen networking engine, Photon Unity Networking, and their usage when synchronizing different types of game information over multiple clients are also discussed. The implemented game retains most of the main features of the modern MOBA games such as heroes with different play styles, skills, team versus team competition, resource collection and consumption, varied maps and defensive structures. The paper concludes with comments on Unity 5 as a MOBA game development environment and execution engine.},
  keywords={Games;Servers;Engines;Photonics;Authentication;Computer architecture;Databases},
  doi={10.23919/MIPRO.2017.7973661},
  ISSN={},
  month={May},}

@INPROCEEDINGS{8802470,
  author={Silva, Pablo Pereira e and Ruas, Vítor Haueisen Costa and Oliveira, Gustavo Coelho Duarte and Martinelli, Tiago Fonseca and de Oliveira, Antônio Victor Machado and Schimidt, Marcelo Queiroz and Andreão, Rodrigo Varejão and Mestria, Mário},
  booktitle={2018 20th Symposium on Virtual and Augmented Reality (SVR)}, 
  title={Workflow to Optimization of 3D Models for Game Development}, 
  year={2018},
  volume={},
  number={},
  pages={225-229},
  abstract={The usage of VR (Virtual Reality) has grown exponentially in the last decade. With various benefits, such as profitability, versatility and practicality, and applications that cover various fields of study, this new form of media has gained its ground in the market. The VR devices, however, have some special requirements for the 3D models it utilizes. The purpose of this paper is to present a workflow to create, with a reduced number of polygons, these 3D models in a way that enables their utilization in virtual reality systems, while also improving the performance of the game engine. There is also a comparison between the models of railway wagons maintenance centers developed with and without the workflow's assistance by evaluating the number of polygons, appearance and performance in the game engine.},
  keywords={virtual reality;optimization;modelling},
  doi={10.1109/SVR.2018.00041},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{6625509,
  author={Page, Wyatt and Schmidt, Brian and Driessen, Peter},
  booktitle={2013 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (PACRIM)}, 
  title={Rendering sound and images together}, 
  year={2013},
  volume={},
  number={},
  pages={395-399},
  abstract={Computer generated images in cinema and games are rendered based on detailed physical models of the scene, resulting in very natural looking (realistic) images as perceived by a human observer. Sound is most often rendered with limited or no reference to these models. Thus the rendered sound does not achieve the level of realism that is potentially available by using the models. In this paper we review methods used for sound mixing and rendering for cinema and games. Acoustic models were standardized in MPEG-4, but are not used widely. Modern cinema sound rendering uses one of the new tools that are popular with cinema directors and producers that do not appear to refer to a scene model. Game sound engines do use scene models for obstructions but not reverberation. For any new method to be successful, it must yield obviously better results with reasonable CPU load and fit into the workflow. A game engine solution is to use the MPEG-4 scene models augmented by adjustable perceptual parameters and convolution with measured reverberation tails. This solution requires a tool and library to enable acoustic properties to be assigned to a visual scene and frequency dependent acoustic distribution (radiation) patterns to be assigned to sound sources.},
  keywords={Games;Visualization;Acoustics;Rendering (computer graphics);Motion pictures;Computational modeling;Computers;auralization;sound and light rendering;sound for computer games},
  doi={10.1109/PACRIM.2013.6625509},
  ISSN={2154-5952},
  month={Aug},}

@INPROCEEDINGS{6949393,
  author={Rojas, Junior},
  booktitle={2013 26th Conference on Graphics, Patterns and Images Tutorials}, 
  title={Getting Started with Videogame Development}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  abstract={This survey provides an overview of various aspects involved in game development. It describes some general concepts, with emphasis on game engine architecture as well as specific technologies related to the described concepts. Covered topics include game graphics rendering, collision detection, physics, artificial intelligence, scripting and game editors.},
  keywords={Games;Engines;Three-dimensional displays;Collision avoidance;Rendering (computer graphics);Physics;Game Engine;Game Development;Videogames},
  doi={10.1109/SIBGRAPI-T.2013.10},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{7300728,
  author={Neto, Mário Popolin and Brega, José Remo Ferreira},
  booktitle={2015 XVII Symposium on Virtual and Augmented Reality}, 
  title={A Survey of Solutions for Game Engines in the Development of Immersive Applications for Multi-projection Systems as Base for a Generic Solution Design}, 
  year={2015},
  volume={},
  number={},
  pages={61-70},
  abstract={Game engines are used in the development of virtual reality applications. They enable developers to focus the virtual environment and spend less time on its creation. The relationship between interactivity and graphics performance offered by game engines has led researchers to explore these engines in multi-projection systems based on the CAVE, which aims to provide an immersive experience through a wide field of view from multiple-screens, stereo images, and perspective correction based on the user's viewpoint. This paper surveys game engine solutions for the development of immersive applications for multi-projection systems in order to point out trends in the usage of these game creation tools for immersive systems and to identify a possible generic solution design.},
  keywords={Games;Engines;Rendering (computer graphics);Synchronization;Servers;Hardware;virtual reality;game engine;multi-projection system},
  doi={10.1109/SVR.2015.16},
  ISSN={},
  month={May},}

@INPROCEEDINGS{8324230,
  author={Meliones, Apostolos and Plas, Ioannis},
  booktitle={2017 Intelligent Systems Conference (IntelliSys)}, 
  title={Developing video games with elementary adaptive artificial intelligence in unity: An intelligent systems approach}, 
  year={2017},
  volume={},
  number={},
  pages={104-111},
  abstract={Video games have increasingly demonstrated a great deal of audiovisual realism, in par with the massive performance improvement of computer systems. At the same time, their Artificial Intelligence (AI) component falls short in terms of realism because it is usually based on non-adaptive methods. Adaptive AI mechanisms can help increase video game realism allowing the game to adapt in real-time to the game progress and the user behavior. Following a short overview of the progress of AI in video games in the past years, this paper highlights the creation of modern video games with basic and elementary adaptive game AI using the Unity game development framework. Particular emphasis is on the details of the AI component. First, a shooter game with basic AI is created. Finally, an action-adventure video game is created featuring elementary case-based adaptive AI. The objective in this game is to create enemies which are able to perceive changes in the environment and adapt their strategies accordingly. Proposed AI practices can migrate into relevant real world applications, such as video surveillance and intrusion detection systems, mission critical autonomous networked patrolling and/or save and rescue robots, vision and hearing assistive applications, intelligent video and behavioral analytics to detect and predict threats etc.},
  keywords={Games;Intelligent systems;Adaptive systems;Real-time systems;Graphics;Task analysis;game AI;adaptive game AI;case-based adaptive game AI;intrusion detection;networked patrolling robots;Unity},
  doi={10.1109/IntelliSys.2017.8324230},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{10169420,
  author={Rodrigues, Lucas Siqueira and Riehm, Felix and Zachow, Stefan and Israel, Johann Habakuk},
  booktitle={2023 9th International Conference on Virtual Reality (ICVR)}, 
  title={VoxSculpt: An Open-Source Voxel Library for Tomographic Volume Sculpting in Virtual Reality}, 
  year={2023},
  volume={},
  number={},
  pages={515-523},
  abstract={Manual processing of tomographic data volumes, such as interactive image segmentation in medicine or paleontology, is considered a time-consuming and cumbersome endeavor. Immersive volume sculpting stands as a potential solution to improve its efficiency and intuitiveness. However, current open-source software solutions do not yield the required performance and functionalities. We address this issue by contributing a novel open-source game engine voxel library that supports real-time immersive volume sculpting. Our design leverages GPU instancing, parallel computing, and a chunk-based data structure to optimize collision detection and rendering. We have implemented features that enable fast voxel interaction and improve precision. Our benchmark evaluation indicates that our implementation offers a significant improvement over the state-of-the-art and can render and modify millions of visible voxels while maintaining stable performance for real-time interaction in virtual reality.},
  keywords={Image segmentation;Graphics processing units;Virtual reality;Manuals;Games;Tomography;Parallel processing;voxel library;volume sculpting;virtual reality},
  doi={10.1109/ICVR57957.2023.10169420},
  ISSN={2331-9569},
  month={May},}

@ARTICLE{7014276,
  author={Mehra, Ravish and Rungta, Atul and Golas, Abhinav and Lin, Ming and Manocha, Dinesh},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={WAVE: Interactive Wave-based Sound Propagation for Virtual Environments}, 
  year={2015},
  volume={21},
  number={4},
  pages={434-442},
  abstract={We present an interactive wave-based sound propagation system that generates accurate, realistic sound in virtual environments for dynamic (moving) sources and listeners. We propose a novel algorithm to accurately solve the wave equation for dynamic sources and listeners using a combination of precomputation techniques and GPU-based runtime evaluation. Our system can handle large environments typically used in VR applications, compute spatial sound corresponding to listener's motion (including head tracking) and handle both omnidirectional and directional sources, all at interactive rates. As compared to prior wave-based techniques applied to large scenes with moving sources, we observe significant improvement in runtime memory. The overall sound-propagation and rendering system has been integrated with the Half-Life 2 game engine, Oculus-Rift head-mounted display, and the Xbox game controller to enable users to experience high-quality acoustic effects (e.g., amplification, diffraction low-passing, high-order scattering) and spatial audio, based on their interactions in the VR application. We provide the results of preliminary user evaluations, conducted to study the impact of wave-based acoustic effects and spatial audio on users' navigation performance in virtual environments.},
  keywords={Runtime;Acoustics;Vectors;Transfer functions;Virtual environments;Linear systems;Navigation;Sound propagation;dynamic sources;spatial sound;Sound propagation;dynamic sources;directivity;spatial sound;Helmholtz equation},
  doi={10.1109/TVCG.2015.2391858},
  ISSN={1941-0506},
  month={April},}

@INPROCEEDINGS{8901975,
  author={Warren, Jonah},
  booktitle={2019 IEEE Games, Entertainment, Media Conference (GEM)}, 
  title={Tiny online game engines}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={A Tiny Online Game Engine (TOGE) is an online tool that allows designers to create small games of a certain genre quickly and easily, often without programming. This paper explores the current landscape of TOGEs by examining three of the most popular engines currently available online: Twine, PuzzleScript, and Bitsy. Each of these tools streamlines the game development process by defining a strict set of constraints affecting the rulesets, aesthetics, and experiences of the games created with it. The design constraints of each engine are examined along with each engine's interface, its design philosophy, a sampling of games published with it, and information gathered from developers who use it. Included in this study is the metadata from 5,001 games and survey results from 163 game developers. Analyzing these engines from a variety of perspectives may help future tool creators identify strategies for making game development more beginner-friendly, accessible, inclusive, and fun.},
  keywords={Games;Engines;Sprites (computer);Philosophical considerations;Hypertext systems;Documentation;Animation;Game development;Game engine;Accessibility;Constraints;Design philosophy},
  doi={10.1109/GEM.2019.8901975},
  ISSN={},
  month={June},}
