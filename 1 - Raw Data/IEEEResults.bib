@INPROCEEDINGS{10585437,
  author={Fransson, Emil and Hermansson, Jonatan and Hu, Yan},
  booktitle={2024 IEEE Gaming, Entertainment, and Media Conference (GEM)}, 
  title={A Comparison of Performance on WebGPU and WebGL in the Godot Game Engine}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={WebGL has been the standard API for rendering graphics on the web over the years. A new technology, WebGPU, has been set to release in 2023 and utilizes many of the novel rendering approaches and features common for the native modern graphics APIs, such as Vulkan. Currently, very limited research exists regarding WebGPU's rasterization capabilities. In particular, no research exists about its capabilities when used as a rendering backend in game engines. This paper aims to investigate performance differences between WebGL and WebGPU. It is done in the context of the game engine Godot, and the measured performance is that of the CPU and GPU frame time. The results show that WebGPU performs better than WebGL when used as a rendering backend in Godot, for both the games tests and the synthetic tests. The comparisons clearly show that WebGPU performs faster in mean CPU and GPU frame time.},
  keywords={Graphics;Graphics processing units;Entertainment industry;Games;Media;Rendering (computer graphics);Particle measurements;Game Engine;Performance Overhead;Rendering;WebGPU;WebGL},
  doi={10.1109/GEM61861.2024.10585437},
  ISSN={2766-6530},
  month={June},}

@INPROCEEDINGS{5430113,
  author={Frapolli, Fulvio and Brocco, Amos and Malatras, Apostolos and Hirsbrunner, Béat},
  booktitle={2010 Third International Conference on Advances in Computer-Human Interactions}, 
  title={FLEXIBLE RULES: A Player Oriented Board Game Development Framework}, 
  year={2010},
  volume={},
  number={},
  pages={113-118},
  abstract={When comparing digital board games with their traditional counterparts, it becomes clear that certain features such as graphics, mundane task automation or saving and restoring the state of the game have been greatly improved.Nonetheless, the transition to a digital environment leads to a loss of the flexibility that makes traditional board games inherently popular. While modifying aspects of the game is straight forward in traditional board games, achieving such a level of customization in the digital domain requires deep knowledge of and access to the game source code. In this paper we focus on board games and by means of an in-depth online survey we validate our previous observation, namely that enhancements should be made to digital board games by incorporating gaming facets found in the physical environment,e.g. support for flexibility by means of house rules. To this end,we introduce a conceptual model for the design of digital board games, which is supported by a set of visual programming tools to enable game development according to the principles set out by our proposed model. The set of the tools along with the underlying intuitive model comprise the FLEXIBLERULES framework, which enables and facilitates flexible and extensible game design and development.},
  keywords={Graphics;Automation;Application software;Informatics;Physics computing;Programming environments;Communication channels;Engines;Logic programming;Computer languages;Games;Survey;Development Framework;Human-Computer Interaction},
  doi={10.1109/ACHI.2010.14},
  ISSN={},
  month={Feb},}

@INPROCEEDINGS{5759223,
  author={Ardouin, Jérôme and Lécuyer, Anatole and Marchal, Maud and Marchand, Eric},
  booktitle={2011 IEEE Symposium on 3D User Interfaces (3DUI)}, 
  title={Design and evaluation of methods to prevent frame cancellation in real-time stereoscopic rendering}, 
  year={2011},
  volume={},
  number={},
  pages={95-98},
  abstract={Frame cancellation comes from the conflict between two depth cues: stereo disparity and occlusion with the screen border. When this conflict occurs, the user suffers from poor depth perception of the scene. It also leads to uncomfortable viewing and eyestrain due to problems in fusing left and right images. In this paper we propose a novel method to avoid frame cancellation in real-time stereoscopic rendering. To solve the disparity/frame occlusion conflict, we propose rendering only the part of the viewing volume that is free of conflict by using clipping methods available in standard real-time 3D APIs. This volume is called the "Stereo Compatible Volume" (SCV) and the method is named "Stereo Compatible Volume Clipping" (SCVC). Black Bands, a proven method initially designed for stereoscopic movies is also implemented to conduct an evaluation. Twenty two people were asked to answer open questions and to score criteria for SCVC, Black Bands and a Control method with no specific treatment. Results show that subjective preference and user's depth perception near screen edge seem improved by SCVC, and that Black Bands did not achieve the performance we expected. At a time when stereoscopic capable hardware is available from the mass consumer market, the disparity/frame occlusion conflict in stereoscopic rendering will become more noticeable. SCVC could be a solution to recommend. SCVC's simplicity of implementation makes the method able to target a wide range of rendering software from VR application to game engine.},
  keywords={Rendering (computer graphics);Real time systems;Motion pictures;Software;Three dimensional displays;Head;Stereoscopy;display technology;visualization;stereo compatible volume;clipping},
  doi={10.1109/3DUI.2011.5759223},
  ISSN={},
  month={March},}

@INPROCEEDINGS{6948472,
  author={Behmel, Andreas and Höhl, Wolfgang and Kienzl, Thomas},
  booktitle={2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={[DEMO] MRI design review system: A mixed reality interactive design review system for architecture, serious games and engineering using game engines, standard software, a tablet computer and natural interfaces}, 
  year={2014},
  volume={},
  number={},
  pages={327-328},
  abstract={Experience and control your design using natural interfaces! Most of todays conventional design review systems require special programming skills for preparation and high-capacity hard- and software for demonstration. Interacting with 3D data sometimes can be complicated. Today we face five major problem fields using design review systems: Interaction with 3D data, navigation in 3D space, controlling design alternatives, design presentation using less extensive hardware, content development without special software and programming skills. Developments also targeting these issues by using different methods are presented e.g. by LANCELLE, SETTGAST and FELLNER (2008). They developed DAVE — Definitely Affordable Virtual Environment at Graz University of Technology. This immersive cage-based system today is used in evaluating the design of the new main railway station in Vienna, Austria. Also SHIRATUDDIN and THABET (2011) utilized the Torque 3D game engine to develop a Virtual Design Review System. Finally DUNSTON et. al. (2011) designed an Immersive Virtual Reality Mock-Up for Design Review of Hospital Patient Rooms. These and other research work was based on standard 3D game engines by using a conventional cave or power wall for presentation and physical immersion. The edddison MRI Design Review System is an easy to use mixed reality interface for design evaluation and presentation. It integrates a wide range of hardware input systems including a special 3D-printed tangible user interface, desktop computers, tablets and touch screens. On the software side it offers plug-ins for standard 3D software including Autodesk Navisworks and Showcase, Unity3D, Trimbles, SketchUp, Web GL and others. The edddison MRI Design Review System enables laymen to create their own interactive 3D content. It is a solution which makes the creation and presentation of interactive 3D applications as simple as preparing a powerpoint presentation. Without any programming skills you can easily manipulate 3D models within standard software applications. Control, change or adapt your design easily and interact with 3D models by natural interfaces and standard handheld devices. Navigate in 3D space using only your tablet computer. Complex buildings can be experienced by means of 2D floor plans and a touchscreen. System requirements are reduced by using standard software applications such as SketchUp or Unity3D. The edddison MRI Design Review System also makes it easy to present different design stages without extensive hard- and software on all common mobile platforms. Actual application areas are Architectural Design, Digital Prototyping, Industrial Simulation, Serious Games and Product Presentation. Currently, the system has two major use-cases: one setup will show the WebGL demo running on an iPad or an Android tablet computer. Using a WebGL/HTML5 cloud solution MRI Design Review System is able to reach the masses. The second demo is a SketchUp file controlled by optical tracking and 3D printed tangible objects also using a touchscreen or a handheld device. The edddison MRI Design Review System extends the range of existing design review systems with an easy-to-use hard- and software. Herein it simplifies the whole design process by an evolutionary, iterative approach, combined with a bunch of user-friendly intuitive interfaces.},
  keywords={Reviews;Three-dimensional displays;Software;Magnetic resonance imaging;Standards;Virtual environments;Solid modeling;Easy to use Mixed-Reality Interface (MRI);User-Friendly Virtual Construction Kit;Building Information Modeling (BIM);Digital Prototyping;3D-Visualization;Serious Games;Unity3D;SketchUp;Autodesk Navisworks;Autodesk Showcase;Unity3D;Trimble;SketchUp;Web GL},
  doi={10.1109/ISMAR.2014.6948472},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{8316417,
  author={Brillantes, Neil Patrick and Kim, Haram and Feria, Rommel and Solamo, Ma. Rowena and Figueroa, Ligaya Leah},
  booktitle={2017 8th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Evaluation of a 3D physics classroom with Myo gesture control armband and unity}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={The quality of Physics education in secondary schools in the Philippines is generally poor. One of the contributing factors identified is the low reliance on technology in the classroom. Thus, a proposal is made for an application entitled Myo Ball which utilizes the Myo gesture control armband and the Unity 3D game engine in order to produce a suitable game-based learning tool for the Physics topic of projectile motion. Myo Ball is able to simulate projectile motion by allowing the user to manipulate a virtual ball using hand gestures and displays proper data from the game engine. This paper discusses at length the software and statistical testing conducted for Myo Ball. Software testing was conducted among high school students in order to assess the controllability, functionality, and usability aspects of Myo Ball, as well as to develop an idea regarding the students' perception of Myo Ball as a learning tool. Statistical tests were conducted to determine the accuracy of the physics values displayed by Myo Ball. It is shown through software testing Myo Ball received highly favorable responses, and students also expressed great interest in Myo Ball as a learning tool. The accuracy of Myo Ball is also proven through the statistical tests, showing that final values displayed by the application have a correctness of at least 95%. Finally, further steps and possible avenues for future development, as suggested during software testing, are outlined.},
  keywords={Games;Tools;Projectiles;Cameras;Three-dimensional displays;Physics;Software testing;Myo Gesture Control Armband;3D Physics Classroom;Learning Tool;Physics Education},
  doi={10.1109/IISA.2017.8316417},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{4592756,
  author={dos Santos, Selan Rodrigues and de Oliveira, Jauvane Cavalvante and Fraga, Luciane Machado and Trenhago, Paulo Roberto and Malfatti, Silvano Maneck},
  booktitle={2008 IEEE Conference on Virtual Environments, Human-Computer Interfaces and Measurement Systems}, 
  title={Using a rendering engine to support the development of immersive virtual reality applications}, 
  year={2008},
  volume={},
  number={},
  pages={74-79},
  abstract={This work presents the features of a flexible realtime 3D graphics engine aimed at the development of multimedia applications and collaborative virtual environments. The engine, called EnCIMA (Engine for Collaborative and Immersive Multimedia Applications), enables a quick development process of applications by providing a high level interface, which has been implemented using the C++ object-oriented programming paradigm. Important characteristics of the engine are the integration of several real time graphics techniques needed by visualization applications; access to network connection management to support collaboration; 3D sound capability; the support to various specialized interaction equipments such as 3D mice, haptic devices, 3D motion trackers, data-gloves, joypads, force feedback joysticks, and; the capacity to have rendering computation and Physics simulation assigned to GPUs and PPUs, respectively. The engine also enables the developer to choose how the scene should be rendered to, i.e. using standard display devices, stereoscopy, or even several simultaneous projection for spatially immersive displays. As part of the evaluation process, we have compared the performance of EnCIMA to a game engine and two scene graph toolkits, through the use of a testbed application.},
  keywords={Engines;Three dimensional displays;Graphics;Collaboration;Solid modeling;Games;Haptic interfaces;Virtual reality engine;immersive application;real time rendering;collaborative virtual reality},
  doi={10.1109/VECIMS.2008.4592756},
  ISSN={1944-9410},
  month={July},}

@INPROCEEDINGS{8747164,
  author={Daineko, Yevgeniya and Ipalakova, Madina and Tsoy, Dana and Bolaov, Zhiger and Yelgondy, Yersultanbek and Shaipiten, Akmedi},
  booktitle={2018 IEEE 12th International Conference on Application of Information and Communication Technologies (AICT)}, 
  title={Development of the educational software based on a game engine}, 
  year={2018},
  volume={},
  number={},
  pages={1-4},
  abstract={In the article the results of the development of educational software based on the game engine Unity 3D for study physics are presented. An overview of virtual educational systems and rationale for selection of a game engine are conducted. The information technologies for the design and development of the virtual laboratory works are described. The distinguishing features of the presented application are identified. Shown, that educational virtual laboratories are the successful examples of application of information technologies in the training process.},
  keywords={Games;Engines;Physics;Software;Three-dimensional displays;Visualization;Education;educational software;virtual experiments;physics;Unity 3D},
  doi={10.1109/ICAICT.2018.8747164},
  ISSN={2472-8586},
  month={Oct},}

@INPROCEEDINGS{6549420,
  author={Luo, Xun},
  booktitle={2013 IEEE Virtual Reality (VR)}, 
  title={Using game engine to enhance mobility modeling in network simulations}, 
  year={2013},
  volume={},
  number={},
  pages={177-178},
  abstract={Mobility modeling is important for network simulation. However, Random Waypoint model and its variants fail to satisfactorily depict mobile users' movement patterns with fidelity. Two features of a game engine, namely character AI and pathfinding can be utilized to enhance mobility modeling in network simulations. This demo builds a virtual scene of typical office environment with multiple employees. Movements of the virtual characters are firstly generated and visualized using Random Waypoint model, and then using alternative approaches combining AI-based control with pathfinding. Through comparison it can be clearly observed that the latter improves simulation fidelity significantly.},
  keywords={Solid modeling;Games;Engines;Artificial intelligence;Visualization;Computational modeling;Mobile computing;Game Engine;Mobility Modeling;Network Simulation},
  doi={10.1109/VR.2013.6549420},
  ISSN={2375-5334},
  month={March},}

@INPROCEEDINGS{7516323,
  author={Yue, Wong Seng},
  booktitle={2015 4th International Conference on Interactive Digital Media (ICIDM)}, 
  title={Enhancement of Learning Management System (LMS) by serious game engine: Collaborative}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  abstract={Recent trend of e-learning system are moving towards gamification, 3D graphics and Virtual Reality (VR), we need to reflect, adapt and utilize new technology in our e-learning system to enhance it so that students can study effectively and efficient. The aim of this research is to gather information concerning Taylor's Integrated Moodle e-Learning System (TIMeS) for supporting collaborative learning. The results of the survey can be used to determine problems of TIMeS during students learning process and other features that need to be adapted in TIMeS for supporting collaborative learning. This paper will present the trend of e-learning system in the literature reviews. The survey results and findings will be discussed and presented. The results have shown that TIMeS still useful for supporting collaborative learning. There are some problems have been identified and need some improvement to enhance and increase students learning. Finally, we present a diagram to propose integrating serious game engine in TIMeS.},
  keywords={Collaborative work;Games;Electronic learning;Engines;Collaborative tools;Electronic mail;Serious game engine;Learning Management System (LMS);Collaborative Learning;e-learning system;enhancement},
  doi={10.1109/IDM.2015.7516323},
  ISSN={},
  month={Dec},}

@ARTICLE{9442261,
  author={Riochet, Ronan and Castro, Mario Ynocente and Bernard, Mathieu and Lerer, Adam and Fergus, Rob and Izard, Véronique and Dupoux, Emmanuel},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={IntPhys 2019: A Benchmark for Visual Intuitive Physics Understanding}, 
  year={2022},
  volume={44},
  number={9},
  pages={5016-5025},
  abstract={In order to reach human performance on complex visual tasks, artificial systems need to incorporate a significant amount of understanding of the world in terms of macroscopic objects, movements, forces, etc. Inspired by work on intuitive physics in infants, we propose an evaluation benchmark which diagnoses how much a given system understands about physics by testing whether it can tell apart well matched videos of possible versus impossible events constructed with a game engine. The test requires systems to compute a physical plausibility score over an entire video. To prevent perceptual biases, the dataset is made of pixel matched quadruplets of videos, enforcing systems to focus on high level temporal dependencies between frames rather than pixel-level details. We then describe two Deep Neural Networks systems aimed at learning intuitive physics in an unsupervised way, using only physically possible videos. The systems are trained with a future semantic mask prediction objective and tested on the possible versus impossible discrimination task. The analysis of their results compared to human data gives novel insights in the potentials and limitations of next frame prediction architectures.},
  keywords={Physics;Task analysis;Visualization;Shape;Predictive models;Motion pictures;Benchmark testing},
  doi={10.1109/TPAMI.2021.3083839},
  ISSN={1939-3539},
  month={Sep.},}

@INPROCEEDINGS{6000320,
  author={Xiang, Yin and Bee, Ng Kian and Dillon, Roberto},
  booktitle={2011 16th International Conference on Computer Games (CGAMES)}, 
  title={Porting and optimizing Music and Emotion Driven Game Engine from PC platform to PS 3 platform}, 
  year={2011},
  volume={},
  number={},
  pages={70-74},
  abstract={Music and Emotion Driven Game Engine (MEDGE) is a music game engine capable of analyzing emotional content in music real-time. As such, its emotion recognition algorithm complexity is computational intensive. This paper studies the MEDGE performance in quantitative terms when it is ported to PS3's multithreading technology — Cell BE platform. We show the experimental results of the increased performance without compromising accuracy of emotion recognition, and illustrate in comparison with Intel Xeon Quad Core system.},
  keywords={Games;Emotion recognition;Computer architecture;Computers;Microprocessors;Feature extraction;Data mining;emotion;music;optimization;porting;PS3},
  doi={10.1109/CGAMES.2011.6000320},
  ISSN={},
  month={July},}

@INPROCEEDINGS{6093238,
  author={Navarro, Andres and Guevara, Dinael and Cardona, Narcis and Gimenez, Jordi J.},
  booktitle={2011 IEEE Vehicular Technology Conference (VTC Fall)}, 
  title={DVB Coverage Prediction Using Game Engine Based Ray-Tracing Techniques}, 
  year={2011},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents the results of an evaluation of a propagation model based on ray-tracing techniques using a game engine and Graphics Processing Unit (GPU) in outdoor scenarios, as a gap-filler for a Digital Video Broadcasting Handheld (DVB-H) service. This model involves complete identification of the parameters of wave propagation, multipath components between the transmitter and the receiver as attenuation, time delay of arrival (TDA), full polarimetric transmission matrix, direction of arrival DoA and the direction of departure DoD. In the paper, we present the results of the simulation and compare them with measurements, obtaining a satisfactory fit.},
  keywords={Ray tracing;Digital video broadcasting;Three dimensional displays;Solid modeling;Engines;Games;Computational modeling},
  doi={10.1109/VETECF.2011.6093238},
  ISSN={1090-3038},
  month={Sep.},}

@INPROCEEDINGS{9951164,
  author={Oakden, Tony and Kavakli, Manolya},
  booktitle={2022 IEEE 42nd International Conference on Distributed Computing Systems Workshops (ICDCSW)}, 
  title={Performance Analysis of RTX Architecture in Virtual Production and Graphics Processing}, 
  year={2022},
  volume={},
  number={},
  pages={215-220},
  abstract={Real-time rendering techniques developed for computer games combined with the improved algorithms and advanced hardware such as the Nvidia Geforce RTX 3000 series of graphic cards improve the quality of the rendered images in CGI. In this paper, our goal is to test the performance of RTX architecture in Virtual Production and graphics processing. We conducted a series of tests for rendering of a scene in Unreal game engine in a Virtual Production studio. Images are rendered in 4K and output to a network distribution system where the image is broken down into a series of smaller images each rendered onto LED screens. The comparison of render times between two graphics workstations using Nvidia RTX A6000 GPU and Nvidia RTX A3090 GPU show that whilst RTX architecture produces better image quality, the gains might not be worth the additional hardware cost required by the high-end graphic cards. It might also be optimal to split the rendering of the scene across multiple computers.},
  keywords={Graphics;Image quality;Costs;Graphics processing units;Production;Computer architecture;Rendering (computer graphics);Real-time rendering;Graphics Processing;Virtual production;Game engineering},
  doi={10.1109/ICDCSW56584.2022.00048},
  ISSN={2332-5666},
  month={July},}

@INPROCEEDINGS{9762415,
  author={Oakden, Tony and Kavakli, Manolya},
  booktitle={2022 14th International Conference on Computer and Automation Engineering (ICCAE)}, 
  title={Graphics Processing in Virtual Production}, 
  year={2022},
  volume={},
  number={},
  pages={61-64},
  abstract={Real-time rendering techniques, developed for computer games, offer great opportunities in Virtual Production. Ray Tracing has been used for CGI movies for many years but it is only recently that its application in real-time has become practical. This is partly due to improved algorithms but mostly advanced hardware such as the Nvidia Geforce RTX 3000 series of cards which provide hardware support for real-time lighting thus improving the quality of the rendered images in CGI. We conducted a series of tests for rendering of a Virtual Production scene in Unreal game engine. Images are rendered in 4K and output to a network distribution system where the image is broken down into a series of smaller images each rendered onto LED screens. Results were plotted to show the comparison of render times between two graphics workstations using Nvidia RTX A6000 GPU cards and Nvidia RTX A3090 GPU. Our findings state that whilst RTX produces better image quality the gains might not be worth the additional hardware cost required by the high-end graphic cards. It might also be optimal to split the rendering of the scene across multiple computers.},
  keywords={Image quality;Graphics;Costs;Graphics processing units;Production;Games;Rendering (computer graphics);graphics processing;virtual production;graphic cards;performance analysis},
  doi={10.1109/ICCAE55086.2022.9762415},
  ISSN={},
  month={March},}

@INPROCEEDINGS{9764924,
  author={Rauch, Róbert and Korečko, Štefan and Gazda, Juraj},
  booktitle={2022 32nd International Conference Radioelektronika (RADIOELEKTRONIKA)}, 
  title={Evaluation of Proximal Policy Optimization with Extensions in Virtual Environments of Various Complexity}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper presents an evaluation of the Proximal Policy Optimization deep reinforcement learning algorithm alone and with several extensions. The extensions used are imitation learning and intrinsic curiosity module. The evaluation takes place in a custom-made racing game, where the goal of an agent, a car, is to complete a racing circuit. The game is implemented in the Unity game engine and the machine learning algorithms are provided by the ML- Agents toolkit. The game provides three levels with racing circuits of different complexity. The results described focus on the hyperparameter search, training progress for all the combinations of the algorithm and the extensions and evaluation in the inference mode.},
  keywords={Training;Machine learning algorithms;Heuristic algorithms;Virtual environments;Games;Reinforcement learning;Inference algorithms;reinforcement learning;Proximal Policy Optimization;evaluation;virtual environment;Unity;ML-Agents},
  doi={10.1109/RADIOELEKTRONIKA54537.2022.9764924},
  ISSN={},
  month={April},}

@INPROCEEDINGS{9110171,
  author={Koh, Eunhak and Park, Gwangsoo and Lee, Byoungjin and Kim, Donggyun and Sung, Sangkyung},
  booktitle={2020 IEEE/ION Position, Location and Navigation Symposium (PLANS)}, 
  title={Performance Validation and Comparison of Range/INS Integrated System in Urban Navigation Environment Using Unity3D and PILS}, 
  year={2020},
  volume={},
  number={},
  pages={788-792},
  abstract={Since the developments of a navigation system that relies mostly on real flight experiments in the GNSS-challenged, urban environments are expensive, the verification and modification process of the prototype system through implementing its simulator takes great advantages. In this study, the objective navigation system under consideration assumes the range/INS integration with an urban GIS map data and GNSS-denied condition. Most fundamentally, in developing the simulator with distributed components, the Unity3D's game engine is adapted as a useful tool for fast map processing and implementing similar flight environments to urban navigation. Moreover, it differentiates itself from other simulators in that it can reduce development costs by making various test runs more comfortable through a manual flight and real-time navigation performance verification. In implementing simulator components, an IMU, multiple rangefinders, barometer, and GPS receiver are modeled considering practical sensor characteristics. Using the measurement difference between the range sensor and the predicted range information calculated from the stored 3D map database in areas of interest, the navigation filter is implemented for combining range residual with INS. The completeness of navigation and simulator is achieved by incorporating the actual noise characteristics observed from real flight tests into the simulator and analyzing estimation performance via mutual comparison.},
  keywords={Urban Navigation;Unity3D;Simulator;GIS},
  doi={10.1109/PLANS46316.2020.9110171},
  ISSN={2153-3598},
  month={April},}

@INPROCEEDINGS{10333229,
  author={Fachada, Nuno and Barreiros, Filipa F. and Lopes, Phil and Fonseca, Micaela},
  booktitle={2023 IEEE Conference on Games (CoG)}, 
  title={Active Learning Prototypes for Teaching Game AI}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Artificial intelligence (AI) in computer games can enhance the player experience by providing more realistic and dynamic interactions with non-player characters and/or the game environment and is, therefore, an essential skill for game development students to acquire. In this paper, we discuss ten active learning prototypes for undergraduate game development students focusing on AI for Games. The prototypes were implemented in the Unity game engine, and each prototype considers a particular technique or set of algorithms. Depending on the prototype, students are required to interact with it on two levels: 1) by running it within the Unity editor, manipulating the respective technique’s parameters, and experimenting and/or playing with the implemented demo or game; or, 2) in addition to the previous level, by actively changing and expanding the provided code to achieve the desired behavior or result. We performed a survey immediately after contact with the prototypes and found that they were easy for the students to manipulate and/or build upon, and most significantly, that they helped students understand the associated techniques and algorithms.},
  keywords={Surveys;Video games;Codes;Education;Prototypes;Focusing;Games;AI for games;AI education;active learning;computer games;game development},
  doi={10.1109/CoG57401.2023.10333229},
  ISSN={2325-4289},
  month={Aug},}

@INPROCEEDINGS{9637178,
  author={Issaee, Arash and Motschnig, Renate and Comber, Oswald},
  booktitle={2021 IEEE Frontiers in Education Conference (FIE)}, 
  title={Pair- versus solo-programming of mini-games as a setting for learning to program: An Action Research approach}, 
  year={2021},
  volume={},
  number={},
  pages={1-9},
  abstract={This Research to Practice Full Paper depicts and evaluates a secondary school project on using pair- and solo-programming of mini-games in introductory programming classes. In addition to investigating various factors influencing students' problem-solving skills (K9; age 14-15), we introduce the software metric Lines Of Code (LOC) to compare outcomes on that specific measure in the pair- and solo-programming setting. The mini-games were developed with the free personal edition of the game development engine Unity™ and C#. In the current study, four different classes at the secondary level were instructed and researched. All classes had approximately the same number of students, the same tasks, the same tutorials, but were using a different social setting for programming. In response to the worldwide pandemic in the years 2020 and 2021, instruction and research proceeded either in virtual or in hybrid-learning mode. We chose participatory action research to accommodate for the complexity of factors inherent in the field as well as for its iterative, cyclic nature. The current cycle is the third of a series on studies that have investigated various aspects of introductory pair-programming. The evaluation phase employs a digital questionnaire with open and closed questions aimed to capture student's perceptions regarding problem solving. In addition, the software metric Lines Of Code” (LOC), traditionally used to measure the size of a computer program by counting the number of lines of the program's source code, was adapted to measure students' achievement in pair- and solo-programming. With our research we aim to contribute to make learning to program more effective, engaging, and inclusive, and we would like to promote 21st century competences besides programming skills. In addition, we are eager to share our practice of pair-programming with educators in order to inspire them to experiment with pair-programming as a social setting with high potential, even in times of required social distancing.},
  keywords={Codes;Software metrics;Current measurement;Tutorials;Size measurement;Encoding;Social factors;pair-programming;solo-programming;students;setting;problem-solving},
  doi={10.1109/FIE49875.2021.9637178},
  ISSN={2377-634X},
  month={Oct},}

@INPROCEEDINGS{9579618,
  author={Vohera, Chaitya and Chheda, Heet and Chouhan, Dhruveel and Desai, Ayush and Jain, Vijal},
  booktitle={2021 12th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Game Engine Architecture and Comparative Study of Different Game Engines}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Nowadays Game Engines have become an integral component of the game development environment. Not only do they accelerate the game development process but also facilitate the integration of gaming modules like animations, graphics, artificial intelligence, and physics using their in-built functionalities. Game Engines also provide a major advantage of reusability of their components making them highly scalable and modifiable. Game engines can be used by the developers to construct and develop games for consoles and different types of platforms such as Android, IOS, Desktop, and many more. This paper eludes the game engine architecture and its constituents and illustrates the features and comparative analysis between four popular game engines namely, Unity, GameMaker, Unreal, and CryEngine. The parameters of this comparison are based on the game engines' technical and non-technical aspects. In conclusion, users will be assisted by the extensive overview provided by this paper in choosing the most preferable engine for their game according to the requirements.},
  keywords={Visualization;Games;Computer architecture;Tools;Animation;Real-time systems;Artificial intelligence;Cry Engine;Game Engine Architecture;GameMaker;Unity;Unreal},
  doi={10.1109/ICCCNT51525.2021.9579618},
  ISSN={},
  month={July},}

@INPROCEEDINGS{10645657,
  author={Macaluso, Girolamo and Sestini, Alessandro and Bagdanov, Andrew D.},
  booktitle={2024 IEEE Conference on Games (CoG)}, 
  title={A Benchmark Environment for Offline Reinforcement Learning in Racing Games}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Offline Reinforcement Learning (ORL) is a promising approach to reduce the high sample complexity of traditional Reinforcement Learning (RL) by eliminating the need for continuous environmental interactions. ORL exploits a dataset of precollected transitions and thus expands the range of application of RL to tasks in which the excessive environment queries increase training time and decrease efficiency, such as in modern AAA games. This paper introduces OfflineMania a novel environment for ORL research. It is inspired by the iconic TrackMania series and developed using the Unity 3D game engine. The environment simulates a single-agent racing game in which the objective is to complete the track through optimal navigation. We provide a variety of datasets to assess ORL performance. These datasets, created from policies of varying ability and in different sizes, aim to offer a challenging testbed for algorithm development and evaluation. We further establish a set of baselines for a range of Online RL, ORL, and hybrid Offline to Online RL approaches using our environment.},
  keywords={Training;Three-dimensional displays;Navigation;Games;Reinforcement learning;Benchmark testing;Complexity theory},
  doi={10.1109/CoG60054.2024.10645657},
  ISSN={2325-4289},
  month={Aug},}

@INPROCEEDINGS{9925955,
  author={Hlavatý, Michal and Kozáková, Alena and Haffner, Oto},
  booktitle={2022 Cybernetics & Informatics (K&I)}, 
  title={Application for Python Programming Language Education Developed by Unity Engine}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Programming is not easy to learn or teach because different students need different explanations to understand such a complex concept. Traditional teaching methods and learning approaches are no longer appropriate for many kids. According to studies, such approaches impair students’ motivation and interest in studying programming. According to research, games can help learn Python programming. The aim of this paper is to present our educational game that we developed in the Unity 3D game engine. The game focuses on pure basics of programming in Python language. Before and after completing the game the player has to fill out a survey that helped us analyze the project.},
  keywords={Graphics;Three-dimensional displays;Education;Games;Programming;Object oriented programming;Programming profession;programming;Python;game;education},
  doi={10.1109/KI55792.2022.9925955},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{7973661,
  author={Polančec, D. and Mekterović, I.},
  booktitle={2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
  title={Developing MOBA games using the Unity game engine}, 
  year={2017},
  volume={},
  number={},
  pages={1510-1515},
  abstract={MOBA (Multiplayer Online Battle Arena) games are currently one of the most popular online video game genres. This paper discusses implementation of a typical MOBA game prototype for Windows platform in a popular game engine Unity 5. The focus is put on using the built-in Unity components in a MOBA setting, developing additional behaviours using Unity's Scripting API for C# and integrating third party components such as the networking engine, 3D models, and particle systems created for use with Unity and available through the Unity Asset Store. A brief overview of useful programming design patterns as well as design patterns already used in Unity is given. Various game state synchronization mechanisms available in the chosen networking engine, Photon Unity Networking, and their usage when synchronizing different types of game information over multiple clients are also discussed. The implemented game retains most of the main features of the modern MOBA games such as heroes with different play styles, skills, team versus team competition, resource collection and consumption, varied maps and defensive structures. The paper concludes with comments on Unity 5 as a MOBA game development environment and execution engine.},
  keywords={Games;Servers;Engines;Photonics;Authentication;Computer architecture;Databases},
  doi={10.23919/MIPRO.2017.7973661},
  ISSN={},
  month={May},}

@INPROCEEDINGS{7824231,
  author={Abdullah, Sukarnur Che and Jusoh, M. Azzeim M. and Nawi, Nazri M. and Amari, M. Dzulhelmy},
  booktitle={2016 International Symposium on Micro-NanoMechatronics and Human Science (MHS)}, 
  title={Robot arm simulation using 3D software application with 3D modeling, programming and simulation support}, 
  year={2016},
  volume={},
  number={},
  pages={1-3},
  abstract={This paper present a new robotics simulator, completely based on Blender 3D and Python as scripting language. The simulation of robot works smoothly with six degree of freedom implemented within it, as the end effector starts to pick the object and to place it, all the links shown their rotation which definitely shown the movement mimics the real movement of robotic arm. The simulation was done with key frame animation and game engine simulation and comparison made relatively to the result obtained.},
  keywords={Animation;End effectors;Games;Engines;Three-dimensional displays},
  doi={10.1109/MHS.2016.7824231},
  ISSN={2474-3771},
  month={Nov},}

@ARTICLE{10286478,
  author={Farkhodov, Khurshedjon and Lee, Suk-Hwan and Platos, Jan and Kwon, Ki-Ryong},
  journal={IEEE Access}, 
  title={Deep Reinforcement Learning Tf-Agent-Based Object Tracking With Virtual Autonomous Drone in a Game Engine}, 
  year={2023},
  volume={11},
  number={},
  pages={124129-124138},
  abstract={The recent development of object-tracking frameworks has affected the performance of many manufacturing and industrial services such as product delivery, autonomous driving systems, security systems, military, transportation and retailing industries, smart cities, healthcare systems, agriculture, etc. Achieving accurate results in physical environments and conditions remains quite challenging for the actual object-tracking. However, the process can be experimented with using simulation techniques or platforms to evaluate and check the model’s performance under different simulation conditions and weather changes. This paper presents one of the target tracking approaches based on the reinforcement learning technique integrated with TensorFlow-Agent (tf-agent) to accomplish the tracking process in the Unreal Game Engine simulation platform AirSim Blocks. The productivity of these platforms can be seen while experimenting in virtual-reality conditions with virtual drone agents and performing fine-tuning to achieve the best or desired performance. In this paper, the tf-agent drone learns how to track an object integration with a deep reinforcement learning process to control the actions, states, and tracking by receiving sequential frames from a simple Blocks environment. The tf-agent model is trained in the AirSim Blocks environment for adaptation to the environment and existing objects in a simulation environment for further testing and evaluation regarding the accuracy of tracking and speed. We tested and compared two approaches, DQN and PPO trackers, and reported results in terms of stability, rewards, and numerical performance.},
  keywords={Drones;Target tracking;Object tracking;Adaptation models;Deep learning;Training;Testing;Reinforcement learning;Virtual environments;Object tracking;object detection;reinforcement learning;AirSim;virtual environment;virtual simulation;tf-agent;unreal game engine},
  doi={10.1109/ACCESS.2023.3325062},
  ISSN={2169-3536},
  month={},}

@ARTICLE{9812593,
  author={Kim, Youngjin and Choi, Yubin and Lee, Young Choon and Han, Hyuck and Kang, Sooyong},
  journal={IEEE Access}, 
  title={E-Render: Enabling UHD-Quality Cloud Gaming Through Edge Rendering}, 
  year={2022},
  volume={10},
  number={},
  pages={72107-72119},
  abstract={Cloud gaming services enable users to enjoy various high-quality computer games without installing them in their devices which may have poor resources. However, it consumes high bandwidth in backbone networks as game videos have to be constantly streamed to client devices, which can be a hindering factor for providing Ultra High Definition (UHD)-quality cloud gaming services whose demands are ever increasing. In this paper, we present a novel cloud gaming architecture, E-Render, in which the graphics engine is separated from the cloud game server and is deployed in the edge for rendering. To realize it, however, we need to effectively reduce the amount and latency of graphics commands transfer from the game engine in the cloud to the graphics engine in the edge server. E-render solves the problem by using novel techniques including multi-granular command deduplication and asynchronous buffer binding. We implement a prototype cloud gaming platform based on the E-Render architecture, and evaluate its performance using four real world games. The evaluation results confirm that E-Render can provide UHD-quality cloud gaming services.},
  keywords={Servers;Cloud gaming;Graphics;Bandwidth;Rendering (computer graphics);Engines;Computer architecture;Cloud gaming;edge service;graphics commands streaming;command deduplication},
  doi={10.1109/ACCESS.2022.3187696},
  ISSN={2169-3536},
  month={},}

@INPROCEEDINGS{4730676,
  author={Yan Jiang and Rui Wang and Zhengdong Liu},
  booktitle={2008 9th International Conference on Computer-Aided Industrial Design and Conceptual Design}, 
  title={A survey of cloth simulation and applications}, 
  year={2008},
  volume={},
  number={},
  pages={765-769},
  abstract={Cloth simulation involves a combination of a large range of techniques, such as mechanical simulation, numerical integration, collision detection, constraints, and rendering techniques for creating garments. In this paper, we present major cloth simulation techniques and central application fields, for instance, garment CAD/CAM, game engine, E-commerce, computer films and fashion shows. Furthermore, based on the proposed techniques, several successful productions of cloth simulation are introduced, which provide guidelines of virtual cloth and outline directions of future research.},
  keywords={Computational modeling;Application software;Clothing;Numerical simulation;Computer simulation;Computer aided manufacturing;CADCAM;Engines;Production;Guidelines;Cloth simulation;Numerical integration;Garment CAD},
  doi={10.1109/CAIDCD.2008.4730676},
  ISSN={},
  month={Nov},}

@ARTICLE{10091796,
  author={Gu, Xinjie and Liu, Gang and Zhang, Xiangbo and Tang, Lili and Zhou, Xihong and Qiu, Weifang},
  journal={IEEE Transactions on Games}, 
  title={Infrared-Visible Synthetic Data from Game Engine for Image Fusion Improvement}, 
  year={2024},
  volume={16},
  number={2},
  pages={291-302},
  abstract={Limited by the shooting scenes and angles of fixed cameras, the existing datasets generally lack many detailed pedestrian models in diverse scenarios. Existing deep learning-based image fusion methods, for this reason, bring about overfitting or insufficient information of fusion results in varying degrees. To address this challenge, A new infrared-visible pedestrian synthetic dataset (GIVF) with a synthetic data tagger (GSDT) is constructed and an improved end-to-end image fusion network (FSGAN) is proposed to validate infrared and visible fusion. In the model, the method uses an auxiliary network to extract features that complement the cascade network of the main path, effectively improving the ability to extract pedestrian texture details. Experimental results show that FSGAN can be well applied to GIVF. By conducting extensive comparative experiments with eight state-of-the-art image fusion methods. FSGAN shows better performance than those comparison methods, especially in the two evaluation indexes visual information fidelity and structural similarity measurement (SSIM). Besides, by comparing the quantitative analysis results of various methods, and evaluating the fusion results of real images in complex environments on other three datasets, we conclude that FSGAN can be better applied to GIVF datasets than other popular methods, and has outstanding performance in generalization.},
  keywords={Games;Feature extraction;Image fusion;Training;Generators;Generative adversarial networks;Synthetic data;Feature supplement;generative adversarial network;image fusion;infrared (IR) and visible image (VIS);synthetic dataSet},
  doi={10.1109/TG.2023.3263001},
  ISSN={2475-1510},
  month={June},}

@INPROCEEDINGS{8802470,
  author={Silva, Pablo Pereira e and Ruas, Vítor Haueisen Costa and Oliveira, Gustavo Coelho Duarte and Martinelli, Tiago Fonseca and de Oliveira, Antônio Victor Machado and Schimidt, Marcelo Queiroz and Andreão, Rodrigo Varejão and Mestria, Mário},
  booktitle={2018 20th Symposium on Virtual and Augmented Reality (SVR)}, 
  title={Workflow to Optimization of 3D Models for Game Development}, 
  year={2018},
  volume={},
  number={},
  pages={225-229},
  abstract={The usage of VR (Virtual Reality) has grown exponentially in the last decade. With various benefits, such as profitability, versatility and practicality, and applications that cover various fields of study, this new form of media has gained its ground in the market. The VR devices, however, have some special requirements for the 3D models it utilizes. The purpose of this paper is to present a workflow to create, with a reduced number of polygons, these 3D models in a way that enables their utilization in virtual reality systems, while also improving the performance of the game engine. There is also a comparison between the models of railway wagons maintenance centers developed with and without the workflow's assistance by evaluating the number of polygons, appearance and performance in the game engine.},
  keywords={virtual reality;optimization;modelling},
  doi={10.1109/SVR.2018.00041},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{1379907,
  author={Abdelbar, A.M. and Ragab, S. and Mitri, S.},
  booktitle={2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541)}, 
  title={Co-evolutionary particle swarm optimization applied to the 7/spl times/7 Seega game}, 
  year={2004},
  volume={1},
  number={},
  pages={243-248},
  abstract={Seega is an ancient Egyptian two-stage board game that, in certain aspects, is more difficult than chess. The two-player game is most commonly played on a 7 /spl times/ 7 board, but is also sometimes played on a 5 /spl times/ 5 or 9 /spl times/ 9 board. In the first and more difficult stage of the game, players take turns placing one disk each on the board until the board contains only one empty cell. In the second stage players take turns moving disks of their color; a disk that becomes surrounded by disks of the opposite color is captured and removed from the board. Building on previous work, on the 5 /spl times/ 5 version of Seega [A.M. Abdelbar et al., 2003], we focus, in this paper, on the 7 /spl times/ 7 board. Our approach employs co-evolutionary particle swarm optimization for the generation of feature evaluation scores. Two separate swarms are used to evolve White players and Black players, respectively; each particle represents feature weights for use in the position evaluation. Experimental results are presented and the performance of the full game engine are discussed.},
  keywords={Particle swarm optimization;Computer science;Feature extraction;Engines;Artificial intelligence;Heart;Minimax techniques;Vectors},
  doi={10.1109/IJCNN.2004.1379907},
  ISSN={1098-7576},
  month={July},}

@INPROCEEDINGS{6625509,
  author={Page, Wyatt and Schmidt, Brian and Driessen, Peter},
  booktitle={2013 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (PACRIM)}, 
  title={Rendering sound and images together}, 
  year={2013},
  volume={},
  number={},
  pages={395-399},
  abstract={Computer generated images in cinema and games are rendered based on detailed physical models of the scene, resulting in very natural looking (realistic) images as perceived by a human observer. Sound is most often rendered with limited or no reference to these models. Thus the rendered sound does not achieve the level of realism that is potentially available by using the models. In this paper we review methods used for sound mixing and rendering for cinema and games. Acoustic models were standardized in MPEG-4, but are not used widely. Modern cinema sound rendering uses one of the new tools that are popular with cinema directors and producers that do not appear to refer to a scene model. Game sound engines do use scene models for obstructions but not reverberation. For any new method to be successful, it must yield obviously better results with reasonable CPU load and fit into the workflow. A game engine solution is to use the MPEG-4 scene models augmented by adjustable perceptual parameters and convolution with measured reverberation tails. This solution requires a tool and library to enable acoustic properties to be assigned to a visual scene and frequency dependent acoustic distribution (radiation) patterns to be assigned to sound sources.},
  keywords={Games;Visualization;Acoustics;Rendering (computer graphics);Motion pictures;Computational modeling;Computers;auralization;sound and light rendering;sound for computer games},
  doi={10.1109/PACRIM.2013.6625509},
  ISSN={2154-5952},
  month={Aug},}

@ARTICLE{8678756,
  author={Egea-Lopez, Esteban and Losilla, Fernando and Pascual-Garcia, Juan and Molina-Garcia-Pardo, Jose Maria},
  journal={IEEE Access}, 
  title={Vehicular Networks Simulation With Realistic Physics}, 
  year={2019},
  volume={7},
  number={},
  pages={44021-44036},
  abstract={Evaluation of cooperative automated driving applications requires the capability of simulating the vehicle and traffic dynamics as well as the communications with a level of accuracy that most of the current tools still lack. In this paper, we explore the use of game engines in hybrid traffic-network simulators. We describe and validate a novel framework based on this approach: Veneris. Our framework is made of a traffic simulator, implemented on the top of the Unity game engine, which includes a realistic vehicle model and a set of driving and lane change behaviors adapted to a 3D environment that reproduces real-world traffic dynamics; a ray-launching propagation simulator on graphics-processing-unit (GPU), called Opal, and a set of modules, which enable bidirectional coupling with the OMNET++ network simulator. The more relevant and novel mechanisms of Veneris are introduced, but further implementation details can be checked on the source code provided in our repository. We discuss the validation tests we have performed and show how it provides accurate results in three key areas: 1) the fidelity of the vehicle dynamics; 2) the recreation of realistic traffic flows, and; 3) the accuracy of the propagation simulation. In addition, the general results of the expected performance are provided.},
  keywords={Solid modeling;Engines;Tools;Vehicle dynamics;Games;Physics;Three-dimensional displays;Game engine;GPU;radio propagation;ray tracing;simulation;traffic;vehicular networks},
  doi={10.1109/ACCESS.2019.2908651},
  ISSN={2169-3536},
  month={},}

@INPROCEEDINGS{6949393,
  author={Rojas, Junior},
  booktitle={2013 26th Conference on Graphics, Patterns and Images Tutorials}, 
  title={Getting Started with Videogame Development}, 
  year={2013},
  volume={},
  number={},
  pages={1-5},
  abstract={This survey provides an overview of various aspects involved in game development. It describes some general concepts, with emphasis on game engine architecture as well as specific technologies related to the described concepts. Covered topics include game graphics rendering, collision detection, physics, artificial intelligence, scripting and game editors.},
  keywords={Games;Engines;Three-dimensional displays;Collision avoidance;Rendering (computer graphics);Physics;Game Engine;Game Development;Videogames},
  doi={10.1109/SIBGRAPI-T.2013.10},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{9548604,
  author={Gezgez, Caner and Kaçar, Elif},
  booktitle={2021 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)}, 
  title={Virtual Character Control by Brain-Computer Interface and Comparison of Performance Metrics}, 
  year={2021},
  volume={},
  number={},
  pages={1-7},
  abstract={Brain-Computer Interface (BCI) is a communication system that allows to create interfaces between the human brain and artificial devices. With the advent of consumer grade EEG devices, BCI-controlled games began to be designed. The designed games have features that can be evaluated in the category of competitive games in the entertainment sector and serious games in the medical domain.In this study; two level 2D game was designed that includes single and multi tasking, which provides virtual character control with both BCI and HCI. Two dissimilar BCI prediction algorithms were used in this game designed using a game engine that supports many platforms. Performance metrics obtained from our experiments designed using the developed game for two different methods, estimation algorithms and levels were compared each other.},
  keywords={Measurement;Human computer interaction;Technological innovation;Estimation;Entertainment industry;Games;Prediction algorithms;Brain-Computer Interface (BCI);Multitasking;Electroencephalography (EEG);Emotiv Epoc+;Mind Controlled Game},
  doi={10.1109/INISTA52262.2021.9548604},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{8368698,
  author={Majid, Mohd Saiful Hazam and Khairunizam, W. and Ikram, K. and Jing, L. M. and Sahyudi, B. N. and Zunaidi, I and Ariffin, Mohd Asri and Bakar, A. S. and Razlan, Z. M},
  booktitle={2018 IEEE 14th International Colloquium on Signal Processing & Its Applications (CSPA)}, 
  title={Performance evaluation of a VR-based arm rehabilitation using movement sequence pattern}, 
  year={2018},
  volume={},
  number={},
  pages={123-128},
  abstract={Every year, 15 million people worldwide suffer a stroke, nearly six million die and another five million are left permanently disabled. Stroke therapy cost time and money while some prove inefficient because it takes time for the treatment to show result. Virtual Reality technology is currently widely applied in physical rehabilitation therapy. This research discusses the use of virtual reality game for arm rehabilitation of post stroke patients. Microsoft Kinect sensor and game engine Unity software use as the development tools to design the virtual reality game. In this study, three arm movement sequence patterns consist of object reaching, arm lifting, grab and release movements was design for the virtual reality game. A healthy volunteer subject was involved to evaluate the performance of the virtual reality game. The result shows that, in VR-based arm rehabilitation using motion sequence pattern 1, the completion time has been improved after three trials where in the last trial, the time taken by the subject to complete the task has been reduced to 10 seconds compare to first trial. Arm rehabilitation using motion sequence pattern 2 also shows improvement where after the third trial, subject was able to complete the task within 18 seconds, which is 14 seconds faster than the first trial whereas in the third movement sequence pattern the time taken to complete the task improves from 20 seconds in the first trial to 14 seconds in the last trial. The questionnaire outcome reveals rehabilitation games show a potential to provide fun, less tiresome, motivation, interesting, safe, and easy to understand rehabilitation activity.},
  keywords={Games;Task analysis;Virtual reality;Muscles;Medical treatment;Tracking;Signal processing;Stroke;Arm Rehabilitation;Virtual Reality Game;Microsoft Kinect;Unity;Motion Sequence Pattern},
  doi={10.1109/CSPA.2018.8368698},
  ISSN={},
  month={March},}

@ARTICLE{7317717,
  author={Fachkha, Claude and Debbabi, Mourad},
  journal={IEEE Communications Surveys & Tutorials}, 
  title={Darknet as a Source of Cyber Intelligence: Survey, Taxonomy, and Characterization}, 
  year={2016},
  volume={18},
  number={2},
  pages={1197-1227},
  abstract={Today, the Internet security community largely emphasizes cyberspace monitoring for the purpose of generating cyber intelligence. In this paper, we present a survey on darknet. The latter is an effective approach to observe Internet activities and cyber attacks via passive monitoring. We primarily define and characterize darknet and indicate its alternative names. We further list other trap-based monitoring systems and compare them to darknet. Moreover, in order to provide realistic measures and analysis of darknet information, we report case studies, namely, Conficker worm in 2008 and 2009, Sality SIP scan botnet in 2011, and the largest amplification attack in 2014. Finally, we provide a taxonomy in relation to darknet technologies and identify research gaps that are related to three main darknet categories: deployment, traffic analysis, and visualization. Darknet projects are found to monitor various cyber threat activities and are distributed in one third of the global Internet. We further identify that Honeyd is probably the most practical tool to implement darknet sensors, and future deployment of darknet will include mobile-based VOIP technology. In addition, as far as darknet analysis is considered, computer worms and scanning activities are found to be the most common threats that can be investigated throughout darknet; Code Red and Slammer/Sapphire are the most analyzed worms. Furthermore, our study uncovers various lacks in darknet research. For instance, less than 1% of the contributions tackled distributed reflection denial of service (DRDoS) amplification investigations, and at most 2% of research works pinpointed spoofing activities. Last but not least, our survey identifies specific darknet areas, such as IPv6 darknet, event monitoring, and game engine visualization methods that require a significantly greater amount of attention from the research community.},
  keywords={Monitoring;IP networks;Internet;Sensors;Taxonomy;Computer crime;Cyber;Darknet;Threats;Security;Intelligence;Cyber Attacks;Distributed Denial of Service (DDoS);Distributed Reflection Denial of Service (DRDoS);Botnet;Worms;Probing;Cyber;darknet;threats;security;intelligence;cyber attacks;distributed denial of service (DDoS);distributed reflection denial of service (DRDoS);botnet;worms;probing},
  doi={10.1109/COMST.2015.2497690},
  ISSN={1553-877X},
  month={Secondquarter},}

@INPROCEEDINGS{7317961,
  author={Runarsson, Thomas Philip and Lucas, Simon M.},
  booktitle={2015 IEEE Conference on Computational Intelligence and Games (CIG)}, 
  title={On imitating Connect-4 game trajectories using an approximate n-tuple evaluation function}, 
  year={2015},
  volume={},
  number={},
  pages={208-213},
  abstract={The effect of game trajectories on learning after-state evaluation functions for the game Connect-4 is investigated. The evaluation function is approximated using a linear function of n-tuple features. The learning is supervised by an AI game engine, called Velena, within a preference learning framework. A different distribution of game trajectories will be generated when applying the learned approximated evaluation function, which may degrade the performance of the player. A technique known as the Dagger method will be used to address this problem. Furthermore, the opponent playing strategy is a source for new game trajectories. Random play will be introduced to the game to model this behaviour. The method of introducing random play to the game will again form different game trajectories and result in various strengths of play learned. An empirical study of a number of techniques for the generation of game trajectories is presented and evaluated.},
  keywords={Games;Trajectory;Training data;Training;Accuracy;Engines;Approximation methods;Connect-4;n-tuples;evaluation function approximation;preference and imitation learning},
  doi={10.1109/CIG.2015.7317961},
  ISSN={2325-4289},
  month={Aug},}

@INPROCEEDINGS{7300728,
  author={Neto, Mário Popolin and Brega, José Remo Ferreira},
  booktitle={2015 XVII Symposium on Virtual and Augmented Reality}, 
  title={A Survey of Solutions for Game Engines in the Development of Immersive Applications for Multi-projection Systems as Base for a Generic Solution Design}, 
  year={2015},
  volume={},
  number={},
  pages={61-70},
  abstract={Game engines are used in the development of virtual reality applications. They enable developers to focus the virtual environment and spend less time on its creation. The relationship between interactivity and graphics performance offered by game engines has led researchers to explore these engines in multi-projection systems based on the CAVE, which aims to provide an immersive experience through a wide field of view from multiple-screens, stereo images, and perspective correction based on the user's viewpoint. This paper surveys game engine solutions for the development of immersive applications for multi-projection systems in order to point out trends in the usage of these game creation tools for immersive systems and to identify a possible generic solution design.},
  keywords={Games;Engines;Rendering (computer graphics);Synchronization;Servers;Hardware;virtual reality;game engine;multi-projection system},
  doi={10.1109/SVR.2015.16},
  ISSN={},
  month={May},}

@INPROCEEDINGS{8324230,
  author={Meliones, Apostolos and Plas, Ioannis},
  booktitle={2017 Intelligent Systems Conference (IntelliSys)}, 
  title={Developing video games with elementary adaptive artificial intelligence in unity: An intelligent systems approach}, 
  year={2017},
  volume={},
  number={},
  pages={104-111},
  abstract={Video games have increasingly demonstrated a great deal of audiovisual realism, in par with the massive performance improvement of computer systems. At the same time, their Artificial Intelligence (AI) component falls short in terms of realism because it is usually based on non-adaptive methods. Adaptive AI mechanisms can help increase video game realism allowing the game to adapt in real-time to the game progress and the user behavior. Following a short overview of the progress of AI in video games in the past years, this paper highlights the creation of modern video games with basic and elementary adaptive game AI using the Unity game development framework. Particular emphasis is on the details of the AI component. First, a shooter game with basic AI is created. Finally, an action-adventure video game is created featuring elementary case-based adaptive AI. The objective in this game is to create enemies which are able to perceive changes in the environment and adapt their strategies accordingly. Proposed AI practices can migrate into relevant real world applications, such as video surveillance and intrusion detection systems, mission critical autonomous networked patrolling and/or save and rescue robots, vision and hearing assistive applications, intelligent video and behavioral analytics to detect and predict threats etc.},
  keywords={Games;Intelligent systems;Adaptive systems;Real-time systems;Graphics;Task analysis;game AI;adaptive game AI;case-based adaptive game AI;intrusion detection;networked patrolling robots;Unity},
  doi={10.1109/IntelliSys.2017.8324230},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{9537063,
  author={Muzahid, Abu Jafar Md and Kamarulzaman, Syafiq Fauzi and Rahman, Md Arafatur},
  booktitle={2021 International Conference on Software Engineering & Computer Systems and 4th International Conference on Computational Science and Information Management (ICSECS-ICOCSIM)}, 
  title={Comparison of PPO and SAC Algorithms Towards Decision Making Strategies for Collision Avoidance Among Multiple Autonomous Vehicles}, 
  year={2021},
  volume={},
  number={},
  pages={200-205},
  abstract={Multiple vehicle collision avoidance strategies with safe lane changing strategy for vehicle control using learning base technique are the most crucial concern in autonomous driving system. Statistics shows that the latest autonomous driving systems are usually prone to rear-end collision. Rear-end collisions often result in severe injuries as well as traffic jam and the consequences are much worse for multiple-vehicle collision. Many previous autonomous driving research focused solely on collision avoidance strategies for two consecutive vehicles. This study proposes a centralised control strategy for multiple vehicles using reinforcement learning focused on partner consideration and goal attainment. The system depicted as a group of vehicles are communicate and coordinate each others by a set of rays and maintain a short following move away. In order to address this challenge, a simulation was implemented in the Unity3D game engine and two state-of-the-art RL algorithms PPO (Proximal Policy Optimization) and SAC (Soft Actor-Critic) were trained by an agent using Unity ML-Agents Toolkit. In terms of success rate, performance, training speed and stability two algorithms are comparable. The potency of algorithms has been assessed by the traffic flow (1) change in vehicle speed, (2) differ in the vehicle beginning positions, and (3) switch to next lane. The agent performed similarly at a 91% success rate in PPO or SAC applications},
  keywords={Training;Scientific computing;Computational modeling;Switches;Reinforcement learning;Stability analysis;Collision avoidance;Autonomous driving;Multiple vehicle collision;Robotics;Reinforcement Learning},
  doi={10.1109/ICSECS52883.2021.00043},
  ISSN={},
  month={Aug},}

@INPROCEEDINGS{10040458,
  author={K, Vigneshwara and M, Dineshkumar and Julie, J. and Anthanesious J, Joshan},
  booktitle={2022 1st International Conference on Computational Science and Technology (ICCST)}, 
  title={Simulation Based Learning System}, 
  year={2022},
  volume={},
  number={},
  pages={878-881},
  abstract={In today's modern world, new discoveries are being made in each and every field and these discoveries led to new opportunities one among those fields is the medical field. This field is further divided into various divisions in which Surgeon's get a special place since they are the one responsible for carrying out most of the emergency cases that arrive at the hospital so to help those surgeons, we have designed a simulation system. Surgical devices nowadays are getting, and the number of people who become physicians are also growing. Medical students must get extensive training, since their job is something which is related to human health major risks can't be taken without proper guidance and also by getting trained regularly their skills can be enhanced. The students are trained by using wide range of equipment, such kind of an equipment is a simulator, which assists the student by providing a real-life experience. Likewise, the simulator we've designed is an EYE Surgery simulator. In this paper, we will discuss about modelling an eye surgery simulator that is both cost-effective and also realistic in every aspect. Immersive VR technology is used in the design process. The main reason of using VR is to get highest level of realism possible while using the simulator. The Unity Game Development Engine is used to produce realistic graphics output while also simplifying the development process. Virtual Reality Surgery Simulation is used in this method to deliver realistic visuals that help trainees to train on surgical skills and also it gives the doctors the confidence to operate on patients. To run the simulation, you'll need to create a desktop application, with high-quality 3D images, the simulation sets a new benchmark in the field of virtual reality used for surgical simulation.},
  keywords={Training;Solid modeling;Visualization;Three-dimensional displays;Computational modeling;Surgery;Virtual reality;simulation system;vr simulation;vr learning;unity framework;surgery simulation;3d simulation},
  doi={10.1109/ICCST55948.2022.10040458},
  ISSN={},
  month={Nov},}

@INPROCEEDINGS{9900900,
  author={Sabet, Saeed Shafiee and Midoglu, Cise and Hassan, Syed Zohaib and Salehi, Pegah and Baugerud, Gunn Astrid and Griwodz, Carsten and Johnson, Miriam and Riegler, Michael Alexander and Halvorsen, Pål},
  booktitle={2022 14th International Conference on Quality of Multimedia Experience (QoMEX)}, 
  title={Comparison of Crowdsourced and Remote Subjective User Studies: A Case Study of Investigative Child Interviews}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Crowdsourced and remote user studies have recently gained popularity as alternatives to traditional laboratory studies. However, they are subject to unreliability, and it is challenging to ensure that valid results are collected, especially when conducting user studies with experts. Experts are a sparse resource, usually having busy schedules and heavy workloads, and are not necessarily geographically close. They are therefore often unwilling to participate in studies which require physical attendance. In this paper, we compare three alternative methods: crowd sourced user study with non-experts, remote user study with non-experts, and remote user study with domain experts, for a use case involving investigative child interview training. We present the results from three subjective studies about the perception of AI-generated child avatars, which is developed using various technologies such as dialogue models, game engine, text-to-speech and speech-to-text components. The study was conducted with three different user groups, and our results indicate the importance of using best practice measures for ensuring the collection of reliable results in crowdsourced settings as compared to remote studies, and highlight the difference between the perspectives of domain experts and non-experts.},
  keywords={Training;Schedules;Correlation;Avatars;Games;Reliability;Interviews;Crowdsourcing;CPS;game engine;talking avatar},
  doi={10.1109/QoMEX55416.2022.9900900},
  ISSN={2472-7814},
  month={Sep.},}

@INPROCEEDINGS{10182944,
  author={A.Faiad, Azza and Abdel-Ghany, Sarah M. and Ayachi, Mohammed and Ahmed, Shehab},
  booktitle={2023 International Wireless Communications and Mobile Computing (IWCMC)}, 
  title={City Scale Digital Twins for Mobility Emissions Evaluation}, 
  year={2023},
  volume={},
  number={},
  pages={1166-1171},
  abstract={The challenges of urbanization and climate change necessitate more sustainable and efficient transport systems, which can be evaluated and optimized in a robust simulation environment before real-world implementation. In this context, a city-scale digital twin can map physical entities and their attributes, structure, state, performance, function, and behavior to the virtual world. It creates a high-fidelity, dynamic, multi-dimensional, multi-scale, and multi-physical model that effectively translates between the real and virtual worlds. Gaming engine-based digital twins can offer visually appealing simulation environments integrating agent-based models widely researched in transportation planning. A digital twin of King Abdullah University of Science and Technology (KAUST) has been developed to assess transportation emissions on campus. Origin/destination data extracted from the simulation were compared to Google Distance Matrix API information. This paper investigates the viability of using the KAUST campus digital twin as a tool for fleet emissions management. The model resulted in a distance deviation of ±0.4 kilometers and a time deviation of ± 10 minutes for the majority of randomly selected trips across the campus for 24 hours. The deviation in distances between the KAUST Digital Twin (KDT) and Google Maps trips results in an error of only 116 g of CO2 per trip. These results suggest that the model provides a potentially accurate simulation environment and hence a credible approach to fleet emissions management. Thus, the KDT can manage fleet emissions, improve transportation efficiency, and improve city-scale performance. Finally, the KDT can contribute towards quantifying the impact of deployment policies and urban planning strategies on a sector basis and their interactions with the UN SDGs 9,11, and 13, particularly in areas currently underserved by existing applications.},
  keywords={Wireless communication;Photography;Web services;Urban planning;Transportation;Data models;Digital twins;Climate change;agent-based models;city-scale planning;transportation;Mobility as a service;GHG emissions},
  doi={10.1109/IWCMC58020.2023.10182944},
  ISSN={2376-6506},
  month={June},}

@INPROCEEDINGS{8325599,
  author={Pouke, Matti and Virtanen, Juho-Pekka and Badri, Mahmoud and Ojala, Timo},
  booktitle={2018 IEEE International Conference on Future IoT Technologies (Future IoT)}, 
  title={Comparison of two workflows for Web-based 3D smart home visualizations}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={In the built environment, the emergence of Internet of Things and the Smart Building paradigm increase the amount of networked systems that produce data from their environment. 3D user interfaces can help users cope with these systems. A 3D representation of a building can operate as a starting point for creating these interfaces. We experimented with creating a 3DUI for sensor network data visualization in two cases, testing both a manually created game engine model and a BIM model as a basis. Solutions were compared in terms of performance. While BIM model captures both the 3D geometry of a building along with its structural properties, some limitations were encountered in using it for online 3D application development.},
  keywords={Data visualization;Three-dimensional displays;Solid modeling;Data models;Smart buildings;Games},
  doi={10.1109/FIOT.2018.8325599},
  ISSN={},
  month={Jan},}

@INPROCEEDINGS{10367391,
  author={Kasim, Muizz and Phon-Amnuaisuk, Somnuk},
  booktitle={2023 6th International Conference on Applied Computational Intelligence in Information Systems (ACIIS)}, 
  title={Glasses-free Autostereoscopic Viewing on Laptop through Spatial Tracking}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper introduces an autostereoscopic viewing method that eliminates the need for specialized 3D glasses. The approach relies on vision-based motion parallax effects achieved by rendering a 3D scene on a 2D display according to the viewer’s head position. Two systems were developed: one employing a single-camera setup, and the other utilizing a dual-camera configuration. By utilizing webcams integrated into a laptop, real-time analysis of the viewer’s head position is performed. A combination of computer vision and range imaging techniques extracts the viewer’s viewing position in the 3D space. This information is then used to manipulate the primary camera object within the Unity game engine, facilitating the rendering of an autostereoscopic view of a 3D scene. The Unity game engine adjusts the scene based on the viewer’s perspective, creating an illusion of a 3D scene on a 2D display as the viewer’s viewpoint changes. The accuracy, range, and output stability of the depth estimation techniques employed in both systems were assessed through systematic evaluation and an application usecase. The systematic evaluation revealed high levels of accuracy in estimating distances from the viewer to the laptop display for both systems, achieved within an effective viewing range of approximately 40 to 160 centimeters. A comprehensive discussion compares the capabilities and performance metrics of the two systems, while the application use-case discussion emphasizes their effectiveness in delivering optimal autostereoscopic viewing on a PC laptop screen.},
  keywords={Three-dimensional displays;Portable computers;Head;Systematics;Two-dimensional displays;Estimation;Games;Autostereoscopic viewing;Range Imaging;Spatial Head Tracking;Unity},
  doi={10.1109/ACIIS59385.2023.10367391},
  ISSN={},
  month={Oct},}

@ARTICLE{8964372,
  author={Tao, Yang and Ganz, Aura},
  journal={IEEE Access}, 
  title={Simulation Framework for Evaluation of Indoor Navigation Systems}, 
  year={2020},
  volume={8},
  number={},
  pages={20028-20042},
  abstract={In this paper, we introduce the first simulation framework that provides cost-effective means to evaluate indoor navigation systems for different user groups (e.g., users with visual impairment), various positioning techniques, and navigation instructions algorithms. The simulation engine uses the Unity game engine, which tracks the virtual user interaction and motion in a virtual environment that represents the physical environment in which the user navigates. The framework includes the following modules that will be defined by the indoor navigation system developers: 1) Positioning module which simulates indoor localization techniques and their observed accuracy; 2) Indoor navigation algorithm module that generates the navigation instructions using natural language phrases, and 3) Virtual user model (VUM) that includes human perception and information processing that can understand navigation instructions, perceive the surrounding environment, and act based on this information. The framework also includes a performance analysis module that evaluates the indoor navigation system performance in terms of navigation success rate and route similarity.},
  keywords={Indoor navigation;Virtual environments;Solid modeling;Games;Sensors;Visualization;Blind and visually impaired;artificial intelligence;natural language processing;wayfinding;PERCEPT;navigation;virtual user model;simulation;ACT-R},
  doi={10.1109/ACCESS.2020.2968435},
  ISSN={2169-3536},
  month={},}

@INPROCEEDINGS{10115968,
  author={Allen, Ross E. and Rachlin, Yaron and Ruprecht, Jessica and Loughran, Sean and Varey, Jacob and Viggh, Herbert},
  booktitle={2023 IEEE Aerospace Conference}, 
  title={SpaceGym: Discrete and Differential Games in Non-Cooperative Space Operations}, 
  year={2023},
  volume={},
  number={},
  pages={1-12},
  abstract={This paper introduces a collection of non-cooperative game environments that are intended to spur development and act as proving grounds for autonomous and AI decision-makers in the orbital domain. SpaceGym comprises two distinct suites of game environments: OrbitDefender2D (OD2D) and the Ker-bal Space Program Differential Games suite (KSPDG). OrbitDe-fender2D consists of discrete, chess-like, two-player gridworld games. OD2D game mechanics are loosely based on orbital motion and players compete to maintain control of orbital slots. The KSPDG suite consists of multi-agent pursuit-evasion differential games constructed within the Kerbal Space Program (KSP) game engine. In comparison to the very limited set of comparable environments in the existing literature, KSPDG represents a much more configurable, extensible, and higher-fidelity aerospace environment suite that leverages a mature game engine to incorporate physics models for phenomenon such as collision mechanics, kinematic chains for deformable bodies, atmospheric drag, variable-mass propulsion, solar irradiance, and thermal models. Both the discrete and differential game suites are built with standardized input/output interfaces based on OpenAI Gym and PettingZoo specifications. This standardization enables-but does not enforce-the use of rein-forcement learning agents within the SpaceGym environments. As a comparison point for future research, we provide baseline agents that employ techniques of model predictive control, numerical differential game solvers, and reinforcement learning-along with their respective performance metrics-for a subset of the SpaceGym environments. The SpaceGym software libraries can be found at https://github.com/mit-II/spacegym-od2d and https://github.com/mit-II/spacegym-kspdg.},
  keywords={Space vehicles;Deformable models;Atmospheric modeling;Games;Differential games;Reinforcement learning;Aerospace electronics},
  doi={10.1109/AERO55745.2023.10115968},
  ISSN={1095-323X},
  month={March},}

@INPROCEEDINGS{7818642,
  author={Kato, Hiromasa and Shimaya, Satoshi and Fujimoto, Keisuke and Kameda, Tomoya and Hong, Tran Thi and Takamaeda-Yamazaki, Shinya and Nakashima, Yasuhiko},
  booktitle={2016 Fourth International Symposium on Computing and Networking (CANDAR)}, 
  title={CPU Meets VR: A Scalable 3D Representation of Manycores for Behavior Analysis}, 
  year={2016},
  volume={},
  number={},
  pages={375-380},
  abstract={Modern microprocessors have a number of cores and complicated structures, such as multi-level caches. Behavior analysis of modern complicated processors is important for software performance optimizations, processor architecture researches, and education purposes. Currently, a number of tools are available for checking the behavior of processors such as processor simulators, debuggers and profilers. However, it takes effort to understand the contents because these tools provide only statistical information such as total count of cache misses. Therefore, in this paper, we propose a novel representation method of internal microprocessor behaviors by using a 3D VR (Virtual Reality) system. The proposed method is scalable to the number of cores on a processor. In order to represent in scalable and efficiently in 3D space, we investigated about the arrangement and shape of the graphics component, and abstract representation of the information. Also, we implemented a prototype system with the proposed method, on"Unity"gaming engine. Our system shows cache miss and number of Instructions Per Cycle (IPC) as the output results of a processor simulator. The evaluation result of the prototype system shows that the system is able to display a wide range of processor configurations on a limited 3D space with acceptable quality of 3D images. So that, our method is suitable for being utilized into the modern many-core processor architectures.},
  keywords={Program processors;Three-dimensional displays;Data visualization;Engines;Prototypes;Image color analysis;visualization;virtual reality;many-core processor;processor simulator;computer architecture},
  doi={10.1109/CANDAR.2016.0072},
  ISSN={2379-1896},
  month={Nov},}

@INPROCEEDINGS{4141628,
  author={Kavakli, Manolya},
  booktitle={2006 7th International Conference on Information Technology Based Higher Education and Training}, 
  title={Training Simulations for Crime Risk Assessment}, 
  year={2006},
  volume={},
  number={},
  pages={203-210},
  abstract={The purpose of this paper is to review training simulations for crime risk assessment and to discuss the system architecture of a training simulation (RiskMan). Computer aided training systems offer a flexible and cost-effective method for learning new skills. The satisfactory management of risk situations involves risk identification, the development of risk handling strategies and plans and the conduct and monitoring of those plans. Recognising the importance of tacit knowledge, scenario-based training has gained importance in recent years. For example, USA General Accounting Office (GAO) released a report on Homeland security titled Risk Management approach can guide preparedness efforts. This report provides a list of risk assessment measurements for contingency plan development and a matrix for risk-based scenario development. In this paper, integrating traditional scenario-based training with desktop VR systems using game engineering, we investigate how a virtual reality training system, which draws on research in the areas of computer games, knowledge acquisition, agent technology and natural language processing, can provide a safe learning experience to assist acquisition of the necessary tacit knowledge. The aim of RiskMan is to train police officers to handle high-risk situations. RiskMan is an ARC Discovery project carried out by the Department of Computing in Macquarie University. RiskMan has been developed using a very-high level scripting language of a game engine, Unreal Tournament 2004. It is composed of modules such as a Scenario-based Expert System, a Narrative Engine, a Game Engine, and a CAD package. RiskMan uses socket connections to feed information between the Narrative Engine and Sim Master to Unreal Tournament Game Engine (UT2004)},
  keywords={Risk management;Management training;Engines;Computational modeling;Virtual reality;Computerized monitoring;Terrorism;Knowledge engineering;Systems engineering and theory;Knowledge acquisition;Games;Training;Simulation;Risk Analysis},
  doi={10.1109/ITHET.2006.339765},
  ISSN={},
  month={July},}

@INPROCEEDINGS{9946323,
  author={Krause-Glau, Alexander and Hasselbring, Wilhelm},
  booktitle={2022 IEEE International Conference on Cloud Engineering (IC2E)}, 
  title={Scalable Collaborative Software Visualization as a Service: Short Industry and Experience Paper}, 
  year={2022},
  volume={},
  number={},
  pages={182-187},
  abstract={Software visualizations are used by software developers, for instance, for program comprehension. In this context, a less researched aspect is the collaborative use of online visual-ization services. This paper presents the conceptual design and a prototype implementation of our approach for a collaborative software visualization service for program comprehension. The central idea is an online available software-as-a-service application that analyzes, persists, and visualizes software applications which users intend to explore and comprehend via software visualization. The resulting implementation is a redevelopment of our live trace visualization tool Explor Viz. In comparison to other approaches, ExplorViz utilizes WebGL and other browser technologies instead of a game engine to render its visualizations. As a result, we achieve a platform-independent interoperability that is crucial for (remote) collaboration. Here, users can explore the same visualization via our collaboratively usable desktop, virtual reality, and also augmented reality modes. Our prototype follows the Twelve-Factor App methodology to build a cloud-native application that comprises multiple scalable microservices. Thanks to horizontal scaling, our implementation is capable to analyze a large amount of visualization data; thus, allowing multiple users to simultaneously use the software visualization service. We conducted a set of preliminary performance exper-iments to benchmark our prototype's scalability. Results show that the evaluated service scales linearly with increasing load.},
  keywords={Cloud computing;Collaborative software;Scalability;Software as a service;Data visualization;Prototypes;Collaboration;program comprehension;software visualization;collaboration;software as a service;extended reality},
  doi={10.1109/IC2E55432.2022.00026},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{10169420,
  author={Rodrigues, Lucas Siqueira and Riehm, Felix and Zachow, Stefan and Israel, Johann Habakuk},
  booktitle={2023 9th International Conference on Virtual Reality (ICVR)}, 
  title={VoxSculpt: An Open-Source Voxel Library for Tomographic Volume Sculpting in Virtual Reality}, 
  year={2023},
  volume={},
  number={},
  pages={515-523},
  abstract={Manual processing of tomographic data volumes, such as interactive image segmentation in medicine or paleontology, is considered a time-consuming and cumbersome endeavor. Immersive volume sculpting stands as a potential solution to improve its efficiency and intuitiveness. However, current open-source software solutions do not yield the required performance and functionalities. We address this issue by contributing a novel open-source game engine voxel library that supports real-time immersive volume sculpting. Our design leverages GPU instancing, parallel computing, and a chunk-based data structure to optimize collision detection and rendering. We have implemented features that enable fast voxel interaction and improve precision. Our benchmark evaluation indicates that our implementation offers a significant improvement over the state-of-the-art and can render and modify millions of visible voxels while maintaining stable performance for real-time interaction in virtual reality.},
  keywords={Image segmentation;Graphics processing units;Virtual reality;Manuals;Games;Tomography;Parallel processing;voxel library;volume sculpting;virtual reality},
  doi={10.1109/ICVR57957.2023.10169420},
  ISSN={2331-9569},
  month={May},}

@INPROCEEDINGS{10169482,
  author={Wang, Mengyan and Yu, Shaopeng and Li, Xiang},
  booktitle={2023 9th International Conference on Virtual Reality (ICVR)}, 
  title={The Path Exploration of University Ideological and Political Courses Based on the Concept of Metaverse}, 
  year={2023},
  volume={},
  number={},
  pages={441-446},
  abstract={The new framework of infrastructure standards for education informatization had been constructed with four levels of digital base, application scenario, system specification and goal guidance, which was combined with the concept of Metaverse in order to improve the quality of ideological and political courses in colleges and universities. The modern history review simulation system was designed by Unity3D game engine and taken as an example, in which C# as the game logic programming language, Node.js as the server programming language, and MySQL as the game database. The path to improve the quality of ideological and political courses had been explored with six key features of new network, new platform, new resources, new campus, new application and new security. The red education resources were introduced into the lessons, and then the transformation of red resources can be realized by the digital technology. It can be seen from the experimental test result, the excellent teaching effect was achieved.},
  keywords={Symbiosis;Metaverse;Logic programming;Education;Games;Virtual reality;Servers;metaverse;ideological and political courses;quality improvement;path exploration},
  doi={10.1109/ICVR57957.2023.10169482},
  ISSN={2331-9569},
  month={May},}

@INPROCEEDINGS{7789680,
  author={Li, Wei and Abtahi, Farnaz and Tsangouri, Christina and Zhu, Zhigang},
  booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Towards an “In-the-Wild” Emotion Dataset Using a Game-Based Framework}, 
  year={2016},
  volume={},
  number={},
  pages={1526-1534},
  abstract={In order to create an "in-the-wild" dataset of facial emotions with large number of balanced samples, this paper proposes a game-based data collection framework. The framework mainly include three components: a game engine, a game interface, and a data collection and evaluation module. We use a deep learning approach to build an emotion classifier as the game engine. Then a emotion web game to allow gamers to enjoy the games, while the data collection module obtains automatically-labelled emotion images. Using our game, we have collected more than 15,000 images within a month of the test run and built an emotion dataset "GaMo". To evaluate the dataset, we compared the performance of two deep learning models trained on both GaMo and CIFE. The results of our experiments show that because of being large and balanced, GaMo can be used to build a more robust emotion detector than the emotion detector trained on CIFE, which was used in the game engine to collect the face images.},
  keywords={Games;Detectors;Machine learning;Emotion recognition;Data collection;Face;Weapons},
  doi={10.1109/CVPRW.2016.190},
  ISSN={2160-7516},
  month={June},}

@INPROCEEDINGS{10226078,
  author={Chen, Ying and Sarik, John and Inaltekin, Hazer and Gorlatova, Maria},
  booktitle={IEEE INFOCOM 2023 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Demo Abstract: Demonstrating Resource-Efficient SLAM in Virtual Spacecraft Environments}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  abstract={The performance of simultaneous localization and mapping (SLAM) systems is impacted by the constrained computation capabilities of mobile devices. Given that the advancement of these systems relies on accurate evaluation of SLAM performance, this issue is exacerbated by the difficulty in evaluating SLAM performance in practice, due to the unavailability of ground truth data. In this demo, we present SpacecraftWalk, a resource-efficient SLAM framework that constructs maps (of the environments) with minimal uncertainty under resource budgets. SpacecraftWalk is evaluated within virtual spacecraft environments (meeting NASA lighting standards) in game engine-based emulators that generate ground truth automatically. Demo participants will navigate in virtual environments while creating their own moving trajectories for evaluating SLAM. They will develop an intuition for how uncertainty-based map construction improves resource efficiency. This demonstration accompanies [1].},
  keywords={Performance evaluation;Space vehicles;Simultaneous localization and mapping;Uncertainty;Navigation;NASA;Virtual environments},
  doi={10.1109/INFOCOMWKSHPS57453.2023.10226078},
  ISSN={2833-0587},
  month={May},}

@INPROCEEDINGS{9231643,
  author={Midtlyng, Mads and Sato, Yuji},
  booktitle={2020 IEEE Conference on Games (CoG)}, 
  title={Lightweight Multi-objective Voice Adaptation for Real-time Speech Interaction Applied in Games}, 
  year={2020},
  volume={},
  number={},
  pages={237-244},
  abstract={This paper proposes a novel voice adaptation method that we applied to interactive activities such as games where source and target data are unaligned. Conventional methods have seen the use of probabilistic models or more recently, Deep Neural Networks. Common for most methods is that they require multiple subjects to train in conjunction, thus voice adaptation is not practical to be used in commercial applications. We propose a method which convert audible frequencies to light spectrum simple RGB color format, and not comparing sound signal similarities, but rather likeness in color. The comparison is done using multi-objective optimization which considers raw and normalized frame colors as two separate objectives to be evaluated, respectively audible and spectral structure. The distance for the objectives is used to select an ideal output frame. Finally, prosodic information such as speech intensity is translated from measured input values onto the designated output frame. The method is evaluated using MOS, ABX, performance benchmark and lastly implemented into the Unity3D game engine as a proof of concept. Results show good sound quality and high performance with little output fragmentation.},
  keywords={Training;Deep learning;Image color analysis;Games;Probabilistic logic;Frequency conversion;Real-time systems;voice adaptation;speech processing;real-time;multi-objective optimization problems;video games},
  doi={10.1109/CoG47356.2020.9231643},
  ISSN={2325-4289},
  month={Aug},}

@INPROCEEDINGS{9935733,
  author={Cisneros, Jhostin and Trujillo, María Fernanda and Rodas, Ana Verónica},
  booktitle={2022 IEEE Sixth Ecuador Technical Chapters Meeting (ETCM)}, 
  title={Workforce training: An application trough an 3DVLE on Unreal Engine}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={This work shows the development of a 3D virtual environment with several interactive interfaces, whose purpose is to be a tool that facilitates the training task of the workforce that operates the vertical packaging machine of TERRAFERTIL S.A. To fulfill this purpose, the environment will emulate the operation and interactively present the calibration for the packaging of crunchy granola in its 340 grams presentation. SolidWorks and Blender are used to model the 3D objects. Subsequently, the “Unreal Engine 4” game engine is used for the creation of the virtual environment, where the 3D objects previously created are imported and the programming of the operating logic, calibration, and user interactions is performed. Finally, the environment is tested to verify its operation and validated through testing by the workers who operate the real machine. Their perception of the environment is collected through a survey and the results are tabulated to rate important aspects of the environment such as its visual validity, physical fidelity, ease of use, and fidelity of the representation of the machine's operation and calibration},
  keywords={Training;Visualization;Three-dimensional displays;Virtual environments;Games;Calibration;Task analysis;3DVLE;Blender;Interactive Interface;SolidWorks;Unreal Engine 4;VFFS Machine},
  doi={10.1109/ETCM56276.2022.9935733},
  ISSN={},
  month={Oct},}

@ARTICLE{10246267,
  author={Lee, Hyunki and Dahouda, Mwamba Kasongo and Joe, Inwhee},
  journal={IEEE Access}, 
  title={Character Behavior Automation Using Deep Reinforcement Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={101435-101442},
  abstract={Recently, various new attempts are being made to improve the quality of media content according to the expansion of the media market. Pre-visualization is one of those attempts, and the behavior of characters (agents) in virtual space is essential for pre-visualization. In this paper, a study was conducted to automatically generate behaviors of virtual characters for more efficient visualization in pre-visualization. In particular, we propose a method to automatically produce an appropriate behavior by detecting the state of the surrounding environment with a deep reinforcement learning technique. A virtual environment is created using a game engine to configure space for reinforcement learning, and a reinforcement learning model of the training environment is configured with Python and PyTorch. The virtual environment and the model training environment are communicated with the ML-agents toolkit. In the virtual environment, the character basically moves in a straight line, and three obstacles appear at random locations in front of the character. The character senses 9 states and allows 5 actions. After that, a reward is offered according to the action to proceed with learning. For performance evaluation, reinforcement learning training was conducted using the Proximal Policy Optimization (PPO) algorithm and Soft Actor-Critic (SAC) algorithm, and performance comparisons were also conducted according to the batch size. As a result, we are able to secure a reinforcement learning model with obstacle avoidance capability. Applying the model to the character proved that the character can automatically animate according to the state of the surrounding environment without explicit programming.},
  keywords={Reinforcement learning;Behavioral sciences;Media;Training;Games;Deep learning;Virtual environments;Pre-visualization;deep reinforcement learning;behavior},
  doi={10.1109/ACCESS.2023.3313737},
  ISSN={2169-3536},
  month={},}

@INPROCEEDINGS{9174589,
  author={Sato, Jonathan and Mediavilla, Chelsea and Ward, Chris M. and Parameswaran, Shibin},
  booktitle={2019 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)}, 
  title={SRC3: A Video Dataset for Evaluating Domain Mismatch}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={In this paper we introduce new video datasets to investigate the gaps between synthetic and real imagery in object detection and depth estimation. Currently, synthetic image datasets with real-world counterparts largely focus on computer vision applications for autonomous driving in unconstrained environments. The high scene complexity of such datasets pose challenges for systematic studies of domain disparities. We aim to create a set of paired datasets to study the discrepancies between the two domains in a more controlled setting. To this end, we have created Synthetic-Real Counterpart 3 (SRC3), which contains multiple datasets with varying levels of scene and object complexity. These versatile datasets span multiple environments and consist of ground-truthed, real-world, and synthetic videos generated using a gaming engine. In addition to the dataset, we present an in-depth analysis and provide comparison benchmarks of these datasets using state-of-the-art detection algorithms. Our results show contrasting performance during cross-domain testing due to differences in image quality and statistics, indicating a need for domain adapted datasets and models.},
  keywords={},
  doi={10.1109/AIPR47015.2019.9174589},
  ISSN={2332-5615},
  month={Oct},}

@INPROCEEDINGS{7868934,
  author={Greiner, Joachim and Oesterlein, Tobias and Lenis, Gustavo and Dössel, Olaf},
  booktitle={2016 Computing in Cardiology Conference (CinC)}, 
  title={Virtual-reality based visualization of cardiac arrhythmias on mobile devices}, 
  year={2016},
  volume={},
  number={},
  pages={1081-1084},
  abstract={Computer simulations and imaging of human physiology and anatomy are effectively used for diagnostics and medical treatments and are thus a focus of scientific research. Suitable representation of data is a critical aspect to achieve best results. Therefore, we developed an interactive visualization scheme especially for the representation of cardiac arrhythmias based on a conventional mobile device and virtual reality (VR) goggles (Google Cardboard and Samsung Gear VR) in combination with a game engine. The aim of this paper is to raise awareness for this new technique, evaluate its potential and propose a general workflow for such a visualization environment. The use of a conventional mobile device in combination with VR goggles creates a portable and low-cost system, equipped with enough processing power and pixel density for many types of applications. The user can interact with the data through head movement or a secondary controller As current game engines support a wide range of additional input methods and controllers, the interaction method can be customized to fit the target audience. To evaluate this method, we conducted a survey with eight typical phenomena from the field of cardiac arrhythmias. The participants were asked to rate different performance aspects on a scale from one (very bad) to five (very good). All participants (N=27) rated the performance as fluent (median=5). Furthermore, most participants (70%) ranked the overall impression as very good (median=5). On the long run, the system can be used for education and presentations as well as improved planning and guidance of medical procedures.},
  keywords={Data visualization;Engines;Mobile handsets;Games;Computational modeling;Eye protection;Solid modeling},
  doi={},
  ISSN={2325-887X},
  month={Sep.},}

@INPROCEEDINGS{8657915,
  author={Hofer, Hansjörg and Seitner, Florian and Gelautz, Margrit},
  booktitle={2018 International Conference on 3D Immersion (IC3D)}, 
  title={An End-to-End System for Real-Time Dynamic Point Cloud Visualization}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={The growing availability of RGB-D data, as delivered by current depth sensing devices, forms the basis for a variety of mixed reality (MR) applications, in which real and synthetic scene content is combined for interaction in real-time. The processing of dynamic point clouds with possible fast and unconstrained movement poses special challenges to the surface reconstruction and rendering algorithms. We propose an end-to-end system for dynamic point cloud visualization from RGB-D input data that takes advantage of the Unity3D game engine for efficient state-of-the-art rendering and platform-independence. We discuss specific requirements and key components of the overall system along with selected aspects of its implementation. Our experimental evaluation demonstrates that high-quality and versatile visualization results can be obtained for datasets of up to 5 million points in real-time.},
  keywords={Three-dimensional displays;Sensors;Data visualization;Surface treatment;Real-time systems;Rendering (computer graphics);Surface reconstruction;point cloud;rendering;real-time;reconstruction;unity3d;visualization;rgb-d},
  doi={10.1109/IC3D.2018.8657915},
  ISSN={2379-1780},
  month={Dec},}

@INPROCEEDINGS{9315039,
  author={Yeasmin, Samira and Albabtain, Layla Abdulrahman},
  booktitle={2020 IEEE Graphics and Multimedia (GAME)}, 
  title={Implementation of a Virtual Reality Escape Room Game}, 
  year={2020},
  volume={},
  number={},
  pages={7-12},
  abstract={The implementation of Virtual Reality (VR) has brought unprecedented meaning to various fields. The application of VR in different areas is bringing revolutionary changes. The gaming field is one of them. The realization of VR in gaming has added a new dimension to this important area. Games have been more interactive, and they have been more enhanced. The use of VR has made gaming more enjoyable. The application of games in education has played a vital role. Therefore, a VR escape room game is proposed to be developed using the Unity3D game engine. The game consists of puzzles that are to be solved to escape the rooms. The game aims to reduce the VR sickness of users while using different VR applications. The goal of the game is to use VR and make players use their skills and utilize their free time effectively. The unique feature of this game is using teleportation for in-game movement to reduce VR sickness. This game promotes testing and enhancing players' skills by making it more interactive with the use of VR. A flowchart, a use case diagram, and an activity diagram have also been designed to explain how the game works. This study analyzes the performance of the escape room game developed. The performance evaluation has been done based on the relationship between time to play the game and VR sickness felt by the users, with and without using teleportation for in-game movement. It includes the limitation of the study as well. Finally, it also presents a future direction for this study and explains how VR sickness can be reduced further in VR applications.},
  keywords={Games;Psychology;Teleportation;Task analysis;Flowcharts;Three-dimensional displays;Performance analysis;Virtual Reality;VR Game;Escape Room Game;VR sickness;Unity3d;C# programming language;VRTK;SteamVR},
  doi={10.1109/GAME50158.2020.9315039},
  ISSN={},
  month={Nov},}

@ARTICLE{10054009,
  author={Ranaweera, Mahesh and Mahmoud, Qusay H.},
  journal={IEEE Access}, 
  title={Bridging the Reality Gap Between Virtual and Physical Environments Through Reinforcement Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={19914-19927},
  abstract={Creating Reinforcement learning(RL) agents that can perform tasks in the real-world robotic systems remains a challenging task due to inconsistencies between the virtual-and the real-world. This is known as the “reality-gap” which hinders the performance of a RL agent trained in a virtual environment. The research describes the techniques used to train the models, generate randomized environments, reward function, and techniques utilized to transfer the model to the physical environment for evaluation. For this investigation, a low-cost 3-degrees-of-freedom (DOF) Steward platform was 3D modeled and created virtually and physically. The goal of the 3D-Stewart platform was to guide and balance the marble towards the center. Custom end-to-end APIs were developed to interact with the Godot game engine, manipulate physics and dynamics, interact with the in-game lighting and perform environment randomizations. Two RL algorithms: Q-learning and Actor-Critic, were implemented to evaluate the performance by using domain randomization and induced noise to bridge the reality gap. For Q-learning, raw frames were used to make predictions while Actor-Critic utilized marble position, velocity vector and relative position by pre-processing captured frames. The experimental results show the effectiveness of domain randomization and introduction of noise during the training.},
  keywords={Robots;Adaptation models;Virtual environments;Training;Q-learning;Transfer learning;Reinforcement learning;Actor-critic;deep Q-learning;reinforcement learning;transfer-learning;sim-to-real;robotics},
  doi={10.1109/ACCESS.2023.3249572},
  ISSN={2169-3536},
  month={},}

@INPROCEEDINGS{8590074,
  author={Tandianus, Budianto and Seah, Hock Soon and Vu, Tuan Dat and Phan, Anh Tú},
  booktitle={2018 International Conference on Cyberworlds (CW)}, 
  title={Cloud-Based Dynamic Streaming and Loading of 3D Scene}, 
  year={2018},
  volume={},
  number={},
  pages={409-414},
  abstract={In this paper, we present an approach for out-of-core dynamic streaming of a virtual scene. We use the traditional client/server architecture, where the main responsibility of the client application is visualization and interaction, and the main responsibility of the server is accepting and serving requests from the client application. The client will query geometry in the camera proximity to the server and the server will stream geometry (in CityGML format) to the client application. We implement the client application using Unity game engine. Performance comparison between traditional loading and our dynamic streaming are provided. We also show the scalability advantage of our work.},
  keywords={Cloud computing;Loading;Three-dimensional displays;Geometry;Engines;Buildings;Games;out-of-core;progressive;cloud;CityGML;Unity},
  doi={10.1109/CW.2018.00079},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{8572120,
  author={Saad, Elie and Funnell, W. Robert J. and Kry, Paul G. and Ventura, Nicole M.},
  booktitle={2018 IEEE Life Sciences Conference (LSC)}, 
  title={A Virtual-Reality System for Interacting with Three-Dimensional Models Using a Haptic Device and a Head-Mounted Display}, 
  year={2018},
  volume={},
  number={},
  pages={191-194},
  abstract={Visualizing and simulating the real world by means of three-dimensional (3D) models is important in many fields, especially in science, technology, engineering and medicine (STEM). Exploiting the human senses, such as the sense of sight with head-mounted displays (HMDs) and the sense of touch with haptic devices, has helped in creating immersive virtual-reality (VR) experiences. However, HMDs and haptics have seldom been combined, and recently the technology has been advancing rapidly in both areas. The objective of this research was to develop a VR system which combines both a consumer-level HMD and a mid-level haptic device using a game-development platform. A proof-of-concept system was developed using the Oculus Rift HMD and the Phantom Premium 1.5 High Force haptic device. The system was implemented using the Unity 3D game engine and was tested with two 3D human anatomical models, a heart and part of a skull. The technical performance of the system was evaluated, and a small preliminary user evaluation was performed. Particular challenges and limitations of currently available hardware and software are also discussed.},
  keywords={Haptic interfaces;Three-dimensional displays;Solid modeling;Resists;Heart;Graphics;Color;virtual reality;3D models;haptics;head-mounted display;anatomy;learning;evaluation},
  doi={10.1109/LSC.2018.8572120},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{10580803,
  author={Molasm, Maryam A. and AbdElrazek, Aida M. and Beshara, Abader Z. and AbdElfattah, Mohamed H. and Abdulaziz, Mahmoud M. and Elshenaway, Abdelghafar R.},
  booktitle={2024 International Conference on Machine Intelligence and Smart Innovation (ICMISI)}, 
  title={A Virtual Pet for Children with Autism Spectrum Disorders (ASD)}, 
  year={2024},
  volume={},
  number={},
  pages={42-45},
  abstract={In Egypt, about 33.6% of children with developmental disabilities have Autism Spectrum Disorder (ASD), social challenges are particularly acute for those with Asperger syndrome, often leading to marginalization and limited opportunities. This project proposes an innovative solution: an Android application featuring an interactive virtual pet companion powered by augmented reality (AR). Developed with the Unity game engine and MediaPipe for pose estimation, the app aims to provide a safe and engaging platform for children with Asperger syndrome to practice social interaction, develop emotional learning skills, and combat social isolation. This project targets children aged 5–12, seeking to improve their social skills, emotional regulation, and engagement with their surroundings through playful interaction with the virtual pet. By addressing the unique needs of children with Asperger syndrome in the Egyptian context, this project has the potential to foster their social integration and well-being, paving the way for a more inclusive future. Evaluation reveals promising results (software-wise), with a 92% effectiveness rate in guiding users toward goals, 93 % efficiency in resource utilization, and manageable technical performance.},
  keywords={Autism;Technological innovation;Accuracy;Pose estimation;Prototypes;Games;Regulation;Augmented Reality (AR);Autism Spectrum Disorder (ASD);Asperger syndrome;Extend Reality (XR);MediaPipe;Unity game engine},
  doi={10.1109/ICMISI61517.2024.10580803},
  ISSN={},
  month={May},}

@ARTICLE{7014276,
  author={Mehra, Ravish and Rungta, Atul and Golas, Abhinav and Lin, Ming and Manocha, Dinesh},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={WAVE: Interactive Wave-based Sound Propagation for Virtual Environments}, 
  year={2015},
  volume={21},
  number={4},
  pages={434-442},
  abstract={We present an interactive wave-based sound propagation system that generates accurate, realistic sound in virtual environments for dynamic (moving) sources and listeners. We propose a novel algorithm to accurately solve the wave equation for dynamic sources and listeners using a combination of precomputation techniques and GPU-based runtime evaluation. Our system can handle large environments typically used in VR applications, compute spatial sound corresponding to listener's motion (including head tracking) and handle both omnidirectional and directional sources, all at interactive rates. As compared to prior wave-based techniques applied to large scenes with moving sources, we observe significant improvement in runtime memory. The overall sound-propagation and rendering system has been integrated with the Half-Life 2 game engine, Oculus-Rift head-mounted display, and the Xbox game controller to enable users to experience high-quality acoustic effects (e.g., amplification, diffraction low-passing, high-order scattering) and spatial audio, based on their interactions in the VR application. We provide the results of preliminary user evaluations, conducted to study the impact of wave-based acoustic effects and spatial audio on users' navigation performance in virtual environments.},
  keywords={Runtime;Acoustics;Vectors;Transfer functions;Virtual environments;Linear systems;Navigation;Sound propagation;dynamic sources;spatial sound;Sound propagation;dynamic sources;directivity;spatial sound;Helmholtz equation},
  doi={10.1109/TVCG.2015.2391858},
  ISSN={1941-0506},
  month={April},}

@INPROCEEDINGS{8099979,
  author={Huang, Shiyu and Ramanan, Deva},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters}, 
  year={2017},
  volume={},
  number={},
  pages={4664-4673},
  abstract={As autonomous vehicles become an every-day reality, high-accuracy pedestrian detection is of paramount practical importance. Pedestrian detection is a highly researched topic with mature methods, but most datasets (for both training and evaluation) focus on common scenes of people engaged in typical walking poses on sidewalks. But performance is most crucial for dangerous scenarios that are rarely observed, such as children playing in the street and people using bicycles/skateboards in unexpected ways. Such in-the-tail data is notoriously hard to observe, making both training and testing difficult. To analyze this problem, we have collected a novel annotated dataset of dangerous scenarios called the Precarious Pedestrian dataset. Even given a dedicated collection effort, it is relatively small by contemporary standards (≈ 1000 images). To explore large-scale data-driven learning, we explore the use of synthetic data generated by a game engine. A significant challenge is selected the right priors or parameters for synthesis: we would like realistic data with realistic poses and object configurations. Inspired by Generative Adversarial Networks, we generate a massive amount of synthetic data and train a discriminative classifier to select a realistic subset (that fools the classifier), which we deem Synthetic Imposters. We demonstrate that this pipeline allows one to generate realistic (or adverserial) training data by making use of rendering/animation engines. Interestingly, we also demonstrate that such data can be used to rank algorithms, suggesting that Synthetic Imposters can also be used for in-the-tail validation at test-time, a notoriously difficult challenge for real-world deployment.},
  keywords={Solid modeling;Three-dimensional displays;Detectors;Engines;Training;Pipelines;Rendering (computer graphics)},
  doi={10.1109/CVPR.2017.496},
  ISSN={1063-6919},
  month={July},}

@ARTICLE{9666899,
  author={Lopez-Gazpio, Inigo},
  journal={IEEE Access}, 
  title={Gaining Student Engagement Through Project-Based Learning: A Competitive 2D Game Construction Case Study}, 
  year={2022},
  volume={10},
  number={},
  pages={1881-1892},
  abstract={In this work we consider an open artificial intelligence game as a matter of study within the lectures of artificial intelligence to combat lack of motivation and increase engagement within the classroom. During formation, students in computer science can deal with moderately complex projects, nevertheless, dealing with such problems is relegated to the Degree Final Project. In this investigation we show the procedural steps of how project-based learning combined with game construction can effectively be used to promote engagement in informatic lectures at university. For the task, we build a 2D game engine and propose students to enroll in factitious research teams with the aim of programming intelligent agents that play the game employing artificial intelligence techniques. The intended principal outcome is to show evidence of the application of project-based learning in artificial intelligence within the lectures, and how it can be combined with game construction to increase motivation in the classroom. Project-based learning has the students learn, organize, and solve challenges while students themselves remain their own responsible for the investigation and process of work. We propose to follow a series of sequential phases that conform a set of milestones that incorporate a project-based learning approach to the lectures. Through this work we show that the use of project-based learning combined with game construction provides reliable evidence that a much deeper understanding about artificial intelligence is attained by students participating in the challenge. Student evaluation questionnaires and final grade results attained by students indicate that students remained more engaged during the semester in comparison to previous semesters in which lack of motivation was reported.},
  keywords={Games;Education;Learning (artificial intelligence);Informatics;Faces;Engines;Task analysis;Action research;active learning computing education;cross-disciplinary skills;engagement;game construction;project-based learning (PBL);reinforcement learning},
  doi={10.1109/ACCESS.2021.3139764},
  ISSN={2169-3536},
  month={},}

@INPROCEEDINGS{8820878,
  author={Pérez-Colado, Víctor Manuel and Pérez-Colado, Iván José and Freire-Morán, Manuel and Martínez-Ortiz, Iván and Fernández-Manjón, Baltasar},
  booktitle={2019 IEEE 19th International Conference on Advanced Learning Technologies (ICALT)}, 
  title={uAdventure: Simplifying Narrative Serious Games Development}, 
  year={2019},
  volume={2161-377X},
  number={},
  pages={119-123},
  abstract={Game engines and developer-friendly authoring tools have greatly simplified entertainment game development. However, this does not extend to serious games which, in particular, require involvement of non-developer stakeholders. We present the first evaluation of uAdventure, an easy-to-use game development environment for narrative point-and-click graphic adventure games. uAdventure is a re-implementation of the previously-validated eAdventure environment on top of the Unity game engine. The idea is to get most of the advantages of the Unity professional environment at a fraction of its complexity, and without requiring programming knowledge to use it. uAdventure include educational-oriented affordances, such as assessment and learning analytics; and has been formatively evaluated by heterogeneous users with different degrees of technical knowledge. The results of our evaluation show much simpler story creation for profiles that had no previous knowledge of the engine, and positive feedback from more technical profiles which would use the tool as a prototyping tool for complex projects.},
  keywords={Games;Engines;Authoring systems;Windows;Tools;Complexity theory;Microsoft Windows;Serious game, authoring system, narrative games, learning analytics},
  doi={10.1109/ICALT.2019.00030},
  ISSN={2161-377X},
  month={July},}

@ARTICLE{9051801,
  author={Chen, Dawei and Liu, Yin-Chen and Kim, BaekGyu and Xie, Jiang and Hong, Choong Seon and Han, Zhu},
  journal={IEEE Transactions on Vehicular Technology}, 
  title={Edge Computing Resources Reservation in Vehicular Networks: A Meta-Learning Approach}, 
  year={2020},
  volume={69},
  number={5},
  pages={5634-5646},
  abstract={With the development of autonomous vehicular technologies, the execution tasks become more memory-consuming and computation-intensive. Simultaneously, a certain portion of tasks are latency-sensitive, such as collaborative perception, path planning, collaborative simultaneous localization and mapping, real-time pedestrian detection, etc. Because of the limited computation resources inside vehicles and restricted transmission bandwidth, edge computing can be an effective way to assist with the tasks execution. Considering from the perspective of business, the reservation or subscription cost is cheaper than real time requests. In order to minimize the expense of consuming edge services, the desirable situation is to reserve the resources as much as needed. However, the configuration of vehicular network is variational in practice due to the diversity of road maps, different time range like peak time and off-peak time, and the various task types, which makes it challenging to figure out a general machine learning model that is suitable for any case. Therefore, to predict the resource consumption in edge nodes accurately in different scenarios, we propose a two-stage meta-learning based approach to adaptively choose the appropriate machine learning algorithms based on the meta-features extracted on database. Besides, due to the deficiency of dataset for edge resource consumption, we program in game engine unity to generate the 3D model of Manhattan area. Meanwhile, we change the factors like different road maps and number of vehicles so as to get closer to practices. In the evaluation part, we adopt root mean square error, mean absolute percentage, and mean GEH as evaluation metrics to assess the performance of each model. Also, a quantitative analysis for the total cost and waste is also conducted. Eventually, we can find that the proposed meta-learning based method outperforms the non-meta ones.},
  keywords={Edge computing;Task analysis;Real-time systems;Autonomous vehicles;Cloud computing;Collaboration;Machine learning;Edge computing;resource reservation;meta-learning;vehicular network},
  doi={10.1109/TVT.2020.2983445},
  ISSN={1939-9359},
  month={May},}

@INPROCEEDINGS{9438374,
  author={Weller, Rene and Schröder, Christoph and Teuber, Jörn and Dittmann, Philipp and Zachmann, Gabriel},
  booktitle={2021 IEEE Aerospace Conference (50100)}, 
  title={VR-Interactions for Planning Planetary Swarm Exploration Missions in VaMEx-Vtb}, 
  year={2021},
  volume={},
  number={},
  pages={1-11},
  abstract={Ahstract-Virtual testbeds (VTBs) are essential for researchers and engineers during the planning, decision making, and testing phases of space missions because they are much faster and cost-effective than physical models or tests. Moreover, they allow to simulate the target conditions that are not available on earth for real-world tests, and it is possible to change or adjust mission parameters or target conditions on-the-fly. However, such highly specialized and flexible tools are often only available as desktop tools with limited visual feedback and a lack of usability. On the other hand, VR is predestinated for easy, natural interaction even in complex decision making and training scenarios, while simultaneously offering high fidelity visual feedback and immersion. We present a novel tool that combines the flexibility of virtual testbeds with an easy-to-use VR interface. To do that, we have extended a VTB for planetary exploration missions, the VaMEx-VTB (Valles Marineris Exploration-VTB), to support sophisticated virtual reality (VR) interactions. The VTB is based on the modern game engine `Unreal Engine 4', which qualifies it for state-of-the-art rendering. Additionally, our system supports a wide variety of different hardware devices, including head-mounted displays (HMDs) and large projection powerwalls with different tracking and input methods. Our VR-VTB enables the users to investigate simulated sensor output and other mission parameters like lines-of-sight or ground formations for a swarm of different spacecraft, including autonomous ground vehicles, flying drones, a humanoid robot, and supporting orbiters. Moreover, the users can directly interact with the virtual environment to distract the swarm units or change environment parameters, like adding boulders or invoking sand storms. Until now, we have used our system for three different scenarios: a swarm-based exploration of the Valles Marineris on planet Mars, a test scenario of the same swarm units on the Canary Islands, and the autonomous building of a moon base. An expert review shows the general usability of our VR-VTB.},
  keywords={Training;Visualization;Decision making;Virtual environments;Tools;Planning;Systems support},
  doi={10.1109/AERO50100.2021.9438374},
  ISSN={1095-323X},
  month={March},}

@INPROCEEDINGS{7590343,
  author={Peters, Erwin and Heijligers, Bram and de Kievith, Josse and Razafindrakoto, Xavier and van Oosterhout, Ruben and Santos, Carlos and Mayer, Igor and Louwerse, Max},
  booktitle={2016 8th International Conference on Games and Virtual Worlds for Serious Applications (VS-GAMES)}, 
  title={Design for Collaboration in Mixed Reality: Technical Challenges and Solutions}, 
  year={2016},
  volume={},
  number={},
  pages={1-7},
  abstract={One of the key challenges in the rapid technological advance of Virtual Reality (VR) and Mixed Reality (MR) concerns the design of collaborative experiences. VR systems do not readily support team collaboration because they tend to focus on individual experiences and do not easily facilitate naturalistic collaboration. MR environments provide solutions for collaborative experiences, but establishing smooth communication between hardware components and software modules faces a major hurdle. This paper presents the background to and main challenges of an ongoing project on collaboration in an MR lab, aiming to design a serious 'team collaboration' game. To this end, we utilized a common game engine to engineer a cost-effective solution that would make the game playable in a configuration operated by WorldViz and Volfoni equipment. Evaluation of various solutions in the development process found a Unity 3D Cluster Rendering Beta solution to be the most cost-effective and successful.},
  keywords={Games;Collaboration;Virtual reality;Engines;Rendering (computer graphics);Three-dimensional displays;Training},
  doi={10.1109/VS-GAMES.2016.7590343},
  ISSN={},
  month={Sep.},}

@INPROCEEDINGS{4270516,
  author={Taylor, Geoffrey R. and Chosak, Andrew J. and Brewer, Paul C.},
  booktitle={2007 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={OVVV: Using Virtual Worlds to Design and Evaluate Surveillance Systems}, 
  year={2007},
  volume={},
  number={},
  pages={1-8},
  abstract={Object video virtual video (OVVV) is a publicly available visual surveillance simulation test bed based on a commercial game engine. The tool simulates multiple synchronized video streams from a variety of camera configurations, including static, PTZ and omni-directional cameras, in a virtual environment populated with computer or player controlled humans and vehicles. To support performance evaluation, OVVV generates detailed automatic ground truth for each frame including target centroids, bounding boxes and pixel-wise foreground segmentation. We describe several realistic, controllable noise effects including pixel noise, video ghosting and radial distortion to improve the realism of synthetic video and provide additional dimensions for performance testing. Several indoor and outdoor virtual environments developed by the authors are described to illustrate the range of testing scenarios possible using OVVV. Finally, we provide a practical demonstration of using OVVV to develop and evaluate surveillance algorithms.},
  keywords={Surveillance;Testing;Computational modeling;Cameras;Virtual environment;Automatic control;Working environment noise;Games;Engines;Computer simulation},
  doi={10.1109/CVPR.2007.383518},
  ISSN={1063-6919},
  month={June},}

@INPROCEEDINGS{8901975,
  author={Warren, Jonah},
  booktitle={2019 IEEE Games, Entertainment, Media Conference (GEM)}, 
  title={Tiny online game engines}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={A Tiny Online Game Engine (TOGE) is an online tool that allows designers to create small games of a certain genre quickly and easily, often without programming. This paper explores the current landscape of TOGEs by examining three of the most popular engines currently available online: Twine, PuzzleScript, and Bitsy. Each of these tools streamlines the game development process by defining a strict set of constraints affecting the rulesets, aesthetics, and experiences of the games created with it. The design constraints of each engine are examined along with each engine's interface, its design philosophy, a sampling of games published with it, and information gathered from developers who use it. Included in this study is the metadata from 5,001 games and survey results from 163 game developers. Analyzing these engines from a variety of perspectives may help future tool creators identify strategies for making game development more beginner-friendly, accessible, inclusive, and fun.},
  keywords={Games;Engines;Sprites (computer);Philosophical considerations;Hypertext systems;Documentation;Animation;Game development;Game engine;Accessibility;Constraints;Design philosophy},
  doi={10.1109/GEM.2019.8901975},
  ISSN={},
  month={June},}

@INPROCEEDINGS{10275500,
  author={Liebert, Artur and Wittke, Christian and Ehrhardt, Jonas and Jaufmann, Richard and Widulle, Niklas and Eilermann, Sebastian and Krantz, Maria and Niggemann, Oliver},
  booktitle={2023 IEEE 28th International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={Using FliPSi to Generate Data for Machine Learning Algorithms}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Cyber-Physical Production Systems (CPPS) are becoming increasingly important in modern manufacturing, which leads to a growing need for automated anomaly detection, maintenance decision-making, and fault diagnosis. Artificial Intelligence (AI) and Machine Learning (ML) algorithms are often used to perform these tasks. However, there is a shortage of real data sets with fault modes, making it difficult to train ML algorithms. To overcome this problem, we propose the use of the Flexible Production Simulation (FliPSi) to generate simulated data for the development, training and evaluation of ML algorithms. FliPSi is a simulation tool developed in Unity, a game engine, which is used to simulate modular CPPS. It allows the construction of different CPPS, data collection, and generating data which could realistically originate from CPPS. The focus of FliPSi is to generate data for the development, training and testing of anomaly detection and diagnosis algorithms. In this paper, we show that data generated with FliPSi can be used to train ML algorithms, specifically recurrent neural networks (RNNs) and variations such as Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), which are specifically designed to process sequential data and that the algorithms trained with these data sets can be employed to detect simulated anomalies. With this, we show that FliPSi can be employed to overcome a blocking issue in using ML algorithms for anomaly detection.},
  keywords={Training;Production systems;Machine learning algorithms;Recurrent neural networks;Training data;Games;Task analysis;Machine Learning;simulation;data;anomaly detection;diagnosis},
  doi={10.1109/ETFA54631.2023.10275500},
  ISSN={1946-0759},
  month={Sep.},}

@INPROCEEDINGS{9916640,
  author={Radwan, Mahmoud Osama and Sedky, Ahmed Ahmed Hesham and Mahar, Khaled Mohammed},
  booktitle={2021 31st International Conference on Computer Theory and Applications (ICCTA)}, 
  title={Obstacles Avoidance of Self-driving Vehicle using Deep Reinforcement Learning}, 
  year={2021},
  volume={},
  number={},
  pages={215-222},
  abstract={Nowadays, there exist different self-driving vehicle functions that allow the vehicle to perform certain actions by itself while the driver is only monitoring it. However, it is difficult in real world to acquire training data for self-driving artificial intelligence algorithms because there are a lot of risks and the need of labeled data. This paper proposes a method to collect training data from Unity game engine’s Machine Learning Toolkit (ML-Agents Toolkit). With this toolkit, Unity allows its users to incorporate Reinforcement Learning (RL) algorithms to train a learning agent. The aim of this paper is to search for the best RL algorithm in order to train the self-driving vehicle to avoid obstacles in a 3D environment. For all study cases, the learning was done by using the two RL learning algorithms Proximal Policy Optimization algorithm (PPO) and Soft Actor-Critic (SAC) algorithm, both using single-instance and multi-instance training. In the data collection from virtual environment to learn, two types of sensors in comparison had been experimented using camera sensors and Light Detection and Ranging (LiDaR) sensors. The results of the research show the advantages and limitations of the used learning algorithms for learning behaviors, the importance of the demonstration provided for the learning algorithms. Experimental results for applying the virtual driving data to drive a vehicle shows the effectiveness of the proposed methodology.},
  keywords={Training;Machine learning algorithms;Three-dimensional displays;Training data;Virtual environments;Reinforcement learning;Sensors;Self-driving Vehicle;Deep Reinforcement Learning;Agents;Artificial Intelligence;Proximal Policy Optimization;Soft Actor-Critic;Light Detection and Ranging;Obstacle avoidance},
  doi={10.1109/ICCTA54562.2021.9916640},
  ISSN={2770-6575},
  month={Dec},}

@INPROCEEDINGS{5949599,
  author={Rohlfshagen, Philipp and Lucas, Simon M.},
  booktitle={2011 IEEE Congress of Evolutionary Computation (CEC)}, 
  title={Ms Pac-Man versus Ghost Team CEC 2011 competition}, 
  year={2011},
  volume={},
  number={},
  pages={70-77},
  abstract={Games provide an ideal test bed for computational intelligence and significant progress has been made in recent years, most notably in games such as Go, where the level of play is now competitive with expert human play on smaller boards. Recently, a significantly more complex class of games has received increasing attention: real-time video games. These games pose many new challenges, including strict time constraints, simultaneous moves and open-endedness. Unlike in traditional board games, computational play is generally unable to compete with human players. One driving force in improving the overall performance of artificial intelligence players are game competitions where practitioners may evaluate and compare their methods against those submitted by others and possibly human players as well. In this pa per we introduce a new competition based on the popular arcade video game Ms Pac-Man: Ms Pac-Man versus Ghost Team. The competition, to be held at the Congress on Evolutionary Computation 2011 for the first time, allows participants to develop controllers for either the Ms Pac-Man agent or for the Ghost Team and unlike previous Ms Pac-Man competitions that relied on screen capture, the players now interface directly with the game engine. In this paper we introduce the competition, including a review of previous work as well as a discussion of several aspects regarding the setting up of the game competition itself.},
  keywords={Games;Artificial intelligence;Real time systems;Humans;Artificial neural networks;Software;Engines;Computational Intelligence;Games;Game Competition;Ms Pac-Man;Predator-Prey},
  doi={10.1109/CEC.2011.5949599},
  ISSN={1941-0026},
  month={June},}

@INPROCEEDINGS{9708400,
  author={Datta, Aniruddha and Bhowmick, Swapnamoy and Kulkarni, Kunal},
  booktitle={2021 International Conference on Advances in Computing and Communications (ICACC)}, 
  title={Learning to play Football using Distributional Reinforcement Learning and Depthwise separable convolution feature extraction}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={In recent years we have seen a huge surge in benchmark tasks for Deep Reinforcement learning algorithms and a tremendous growth in the field of reinforcement learning itself but oftentimes the stochasticity and real time decision making of real world strategic and competitive games and also the choice between a multitude of actions are not mirrored in the environments used for RL agents. To address this issue Google released Gfootball, a football game engine based environment which was popularized by Manchester City FC sponsoring a Kaggle competition but the majority methods revolved around Rule based RL agent, imitation learning, reward modifications etc. and the pure reinforcement learning included feature extractors which had parallel neural networks on costly hardware. We propose a much simpler method involving depthwise separable convolutions as the base feature extractor which yields competitive results across a lot of benchmarks in very few episodes compared to the original paper. We also used Quantile regression DQN due to highly stochastic nature of the environment to exploit the quantiles of the return distribution to improve performance.},
  keywords={Urban areas;Neural networks;Reinforcement learning;Games;Benchmark testing;Feature extraction;Real-time systems;Football;Depthwise convolutions;competitive results;distributional reinforcement learning;QR-DQN;quantiles;quantile regression},
  doi={10.1109/ICACC-202152719.2021.9708400},
  ISSN={},
  month={Oct},}

@INPROCEEDINGS{5971855,
  author={Schönauer, Christian and Pintaric, Thomas and Kaufmann, Hannes and Jansen - Kosterink, Stephanie and Vollenbroek-Hutten, Miriam},
  booktitle={2011 International Conference on Virtual Rehabilitation}, 
  title={Chronic pain rehabilitation with a serious game using multimodal input}, 
  year={2011},
  volume={},
  number={},
  pages={1-8},
  abstract={Rehabilitation for chronic pain follows a multidisciplinary approach, which despite the effort, often lacks the long term success and patients often fail to translate the skills learned in therapy to every day life. Serious games are hypothesized to support patients to self manage their complaints and keep training their physical functions by themselves, especially, when the game is controlled by the patient's own body performance. In this paper we present the implementation of a system providing multimodal input, including our own full body motion capture system, a low cost motion capture system (Microsoft Kinect) and biosignal acquisition devices to a game engine. In addition, a workflow has been established, that enables the use of the acquired multimodal data for serious games in a medical environment. Finally, a serious game has been implemented, targeting rehabilitation of patients with chronic pain of the lower back and neck. The focus of this work is on the multimodal input and how it is used in a game to support rehabilitation of chronic pain patients. A brief comparison of a marker-based full body MoCap system and Microsoft's Kinect is included. Preliminary results of tests currently underway are provided.},
  keywords={Games;Skeleton;Pain;Cameras;Muscles;Tracking;Calibration;Chronic Pain Rehabilitation;Serious Games;Multimodal Input;Full Body Interaction},
  doi={10.1109/ICVR.2011.5971855},
  ISSN={2331-9569},
  month={June},}

@INPROCEEDINGS{7300733,
  author={Zampronio, Guilherme Bezerra and Raposo, Alberto Barbosa and Gattass, Marcelo},
  booktitle={2015 XVII Symposium on Virtual and Augmented Reality}, 
  title={A 3D Simulation System for Emergency Evacuation in Offshore Platforms}, 
  year={2015},
  volume={},
  number={},
  pages={99-106},
  abstract={An application for evacuation simulation using computational resources may help previewing situations, flows, conflicts, and behaviours that may only happen in a real danger situation. This kind of application enables the execution of several pre-defined scenarios at any time, without the expensive and complex allocation of real people. This paper proposes an emergency simulation system on oil platforms in 3D with real-time results using as architecture a game engine (Unity). The solution developed was tested in of real platforms models for comparison with times obtained in emergency simulations with people. System performance will be exposed, as well as future works.},
  keywords={Computational modeling;Three-dimensional displays;Engines;Software;Solid modeling;Games;Visualization;Emergency Simulation;Crowd;Game Engines;Oil & Gas;3D},
  doi={10.1109/SVR.2015.21},
  ISSN={},
  month={May},}

@INPROCEEDINGS{8490973,
  author={Zhang, Yi and Qiu, Weichao and Chen, Qi and Hu, Xiaolin and Yuille, Alan},
  booktitle={2018 International Conference on 3D Vision (3DV)}, 
  title={UnrealStereo: Controlling Hazardous Factors to Analyze Stereo Vision}, 
  year={2018},
  volume={},
  number={},
  pages={228-237},
  abstract={A reliable stereo algorithm is critical for many robotics applications. But textureless and specular regions can easily cause failure by making feature matching difficult. Understanding whether an algorithm is robust to these hazardous regions is important. Although many stereo benchmarks have been developed to evaluate performance, it is hard to quantify the effect of hazardous regions in real images because the location and severity of these regions are unknown. In this paper, we develop a synthetic image generation tool enabling to control hazardous factors, such as making objects more specular or transparent, to produce hazardous regions at different degrees. The densely controlled sampling strategy in virtual worlds enables to effectively stress test stereo algorithms by varying the types and degrees of the hazard. We generate a large synthetic image dataset with automatically computed hazardous regions and analyze algorithms on these regions. The observations from synthetic images are further validated by annotating hazardous regions in real-world datasets Middlebury and KITTI (which gives a sparse sampling of the hazards). Our synthetic image generation tool is based on a game engine Unreal Engine 4 and will be open-source along with the virtual scenes in our experiments. Many publicly available realistic game contents can be used by our tool to provide an enormous resource for development and evaluation of algorithms.},
  keywords={Tools;Three-dimensional displays;Robustness;Cameras;Games;Engines;Solid modeling;stereo;dataset;robustness},
  doi={10.1109/3DV.2018.00035},
  ISSN={2475-7888},
  month={Sep.},}
